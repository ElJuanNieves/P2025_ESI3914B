{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../labs/img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "### <center> **Procesamiento de Datos Masivos** </center>\n",
    "---\n",
    "### <center> **Primavera 2025** </center>\n",
    "---\n",
    "**Primer Examen**\n",
    "\n",
    "**Fecha**: 14 de Marzo del 2025\n",
    "\n",
    "**Nombre del estudiante**:\n",
    "\n",
    "**Professor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/14 13:43:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkSQL-Exam-1-ANGEL-CORTES\") \\\n",
    "    .master(\"spark://873bad4e62fe:7077\") \\\n",
    "    .config(\"spark.ui.port\",\"4040\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Read the Data (10 points):\n",
    "Load the employees.csv and departments.csv files into PySpark DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- department_id: integer (nullable = true)\n",
      " |-- department_name: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------------+---------+\n",
      "|department_id|department_name       |location |\n",
      "+-------------+----------------------+---------+\n",
      "|101          |Human Resources       |San Diego|\n",
      "|102          |Finance and Accounting|New York |\n",
      "|103          |Sales and Marketing   |Chicago  |\n",
      "|104          |Data Engineering      |Zapopan  |\n",
      "|105          |Data Science          |Seattle  |\n",
      "+-------------+----------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- employee_id: integer (nullable = true)\n",
      " |-- employee_info: string (nullable = true)\n",
      "\n",
      "+-----------+-------------------------------------------------------------------------------------------+\n",
      "|employee_id|employee_info                                                                              |\n",
      "+-----------+-------------------------------------------------------------------------------------------+\n",
      "|1          |{'name': 'Caitlyn', 'department_id': 103, 'salary': 115959.78, 'hire_date': '2002-06-10'}  |\n",
      "|2          |{'name': 'Rachel', 'department_id': 104, 'salary': 100820.16, 'hire_date': '2009-07-01'}   |\n",
      "|3          |{'name': 'Carrie', 'department_id': 105, 'salary': 114421.44, 'hire_date': '1998-12-10'}   |\n",
      "|4          |{'name': 'Renee', 'department_id': 104, 'salary': 54688.13, 'hire_date': '1995-03-17'}     |\n",
      "|5          |{'name': 'Gabriella', 'department_id': 109, 'salary': 106267.03, 'hire_date': '1995-02-09'}|\n",
      "+-----------+-------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "\n",
    "departments_schema = StructType([\n",
    "    StructField(\"department_id\", IntegerType(), True),\n",
    "    StructField(\"department_name\", StringType(), True),\n",
    "    StructField(\"location\", StringType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "employees_schema = StructType([\n",
    "    StructField(\"employee_id\", IntegerType(), True),\n",
    "    StructField(\"employee_info\", StringType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "departments_df = spark.read \\\n",
    "    .schema(departments_schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(\"/home/jovyan/notebooks/data/departments.csv\")\n",
    "\n",
    "\n",
    "employees_df = spark.read \\\n",
    "    .schema(employees_schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(\"/home/jovyan/notebooks/data/employees.csv\")\n",
    "\n",
    "\n",
    "departments_df.printSchema()\n",
    "departments_df.show(5, truncate=False)\n",
    "\n",
    "employees_df.printSchema()\n",
    "employees_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extract the employee info from the JSON column (20 points):\n",
    "Extract the following the columns: name (string), department_id (integer), salary (double), and hire_date (date) from the employee_info column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- department_id: integer (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      " |-- hire_date: date (nullable = true)\n",
      "\n",
      "+-----------+---------+-------------+---------+----------+\n",
      "|employee_id|name     |department_id|salary   |hire_date |\n",
      "+-----------+---------+-------------+---------+----------+\n",
      "|1          |Caitlyn  |103          |115959.78|2002-06-10|\n",
      "|2          |Rachel   |104          |100820.16|2009-07-01|\n",
      "|3          |Carrie   |105          |114421.44|1998-12-10|\n",
      "|4          |Renee    |104          |54688.13 |1995-03-17|\n",
      "|5          |Gabriella|109          |106267.03|1995-02-09|\n",
      "|6          |Kristen  |101          |88237.54 |2010-11-15|\n",
      "|7          |Jonathan |102          |39323.42 |2012-06-30|\n",
      "|8          |Michelle |101          |64262.85 |2005-10-30|\n",
      "|9          |Michelle |105          |103521.88|1991-07-10|\n",
      "|10         |Lisa     |110          |55435.93 |2016-03-25|\n",
      "+-----------+---------+-------------+---------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType\n",
    "\n",
    "\n",
    "employee_info_schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"department_id\", IntegerType(), True),\n",
    "    StructField(\"salary\", DoubleType(), True),\n",
    "    StructField(\"hire_date\", DateType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "employees_parsed_df = employees_df.withColumn(\n",
    "    \"parsed_info\", \n",
    "    from_json(col(\"employee_info\"), employee_info_schema)\n",
    ")\n",
    "\n",
    "\n",
    "employees_extracted_df = employees_parsed_df.select(\n",
    "    col(\"employee_id\"),\n",
    "    col(\"parsed_info.name\"),\n",
    "    col(\"parsed_info.department_id\").alias(\"department_id\"),\n",
    "    col(\"parsed_info.salary\").alias(\"salary\"),\n",
    "    col(\"parsed_info.hire_date\")\n",
    "  \n",
    ")\n",
    "\n",
    "\n",
    "employees_extracted_df.printSchema()\n",
    "employees_extracted_df.show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Join Operations (10 points):\n",
    "Join the employees DataFrame with the departments DataFrame on department_id to enrich the employee data with department details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame enriquecido con información de departamentos:\n",
      "root\n",
      " |-- employee_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- department_id: integer (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      " |-- hire_date: date (nullable = true)\n",
      " |-- department_name: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      "\n",
      "+-----------+---------+-------------+---------+----------+-------------------------------------------+-------------+\n",
      "|employee_id|name     |department_id|salary   |hire_date |department_name                            |location     |\n",
      "+-----------+---------+-------------+---------+----------+-------------------------------------------+-------------+\n",
      "|1          |Caitlyn  |103          |115959.78|2002-06-10|Sales and Marketing                        |Chicago      |\n",
      "|2          |Rachel   |104          |100820.16|2009-07-01|Data Engineering                           |Zapopan      |\n",
      "|3          |Carrie   |105          |114421.44|1998-12-10|Data Science                               |Seattle      |\n",
      "|4          |Renee    |104          |54688.13 |1995-03-17|Data Engineering                           |Zapopan      |\n",
      "|5          |Gabriella|109          |106267.03|1995-02-09|Customer Service                           |San Francisco|\n",
      "|6          |Kristen  |101          |88237.54 |2010-11-15|Human Resources                            |San Diego    |\n",
      "|7          |Jonathan |102          |39323.42 |2012-06-30|Finance and Accounting                     |New York     |\n",
      "|8          |Michelle |101          |64262.85 |2005-10-30|Human Resources                            |San Diego    |\n",
      "|9          |Michelle |105          |103521.88|1991-07-10|Data Science                               |Seattle      |\n",
      "|10         |Lisa     |110          |55435.93 |2016-03-25|Corporate Strategy and Business Development|Los Angeles  |\n",
      "+-----------+---------+-------------+---------+----------+-------------------------------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enriched_employees_df = employees_extracted_df.join(\n",
    "    departments_df,\n",
    "    employees_extracted_df[\"department_id\"] == departments_df[\"department_id\"],\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "\n",
    "enriched_employees_df = enriched_employees_df.drop(departments_df[\"department_id\"])\n",
    "\n",
    "\n",
    "print(\"DataFrame enriquecido con información de departamentos:\")\n",
    "enriched_employees_df.printSchema()\n",
    "enriched_employees_df.show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Transformations (Using when()) (10 points):\n",
    "Add a new column salary_category to the enriched employee DataFrame:\n",
    "\n",
    "If salary is greater than or equal to 55000, set salary_category to \"High\".\n",
    "\n",
    "Otherwise, set salary_category to \"Low\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame con columna salary_category:\n",
      "root\n",
      " |-- employee_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- department_id: integer (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      " |-- hire_date: date (nullable = true)\n",
      " |-- department_name: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- salary_category: string (nullable = false)\n",
      "\n",
      "+-----------+---------+-------------+---------+----------+-------------------------------------------+-------------+---------------+\n",
      "|employee_id|name     |department_id|salary   |hire_date |department_name                            |location     |salary_category|\n",
      "+-----------+---------+-------------+---------+----------+-------------------------------------------+-------------+---------------+\n",
      "|1          |Caitlyn  |103          |115959.78|2002-06-10|Sales and Marketing                        |Chicago      |High           |\n",
      "|2          |Rachel   |104          |100820.16|2009-07-01|Data Engineering                           |Zapopan      |High           |\n",
      "|3          |Carrie   |105          |114421.44|1998-12-10|Data Science                               |Seattle      |High           |\n",
      "|4          |Renee    |104          |54688.13 |1995-03-17|Data Engineering                           |Zapopan      |Low            |\n",
      "|5          |Gabriella|109          |106267.03|1995-02-09|Customer Service                           |San Francisco|High           |\n",
      "|6          |Kristen  |101          |88237.54 |2010-11-15|Human Resources                            |San Diego    |High           |\n",
      "|7          |Jonathan |102          |39323.42 |2012-06-30|Finance and Accounting                     |New York     |Low            |\n",
      "|8          |Michelle |101          |64262.85 |2005-10-30|Human Resources                            |San Diego    |High           |\n",
      "|9          |Michelle |105          |103521.88|1991-07-10|Data Science                               |Seattle      |High           |\n",
      "|10         |Lisa     |110          |55435.93 |2016-03-25|Corporate Strategy and Business Development|Los Angeles  |High           |\n",
      "+-----------+---------+-------------+---------+----------+-------------------------------------------+-------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, lit\n",
    "\n",
    "enriched_employees_df = enriched_employees_df.withColumn(\n",
    "    \"salary_category\",\n",
    "    when(col(\"salary\") >= 55000, \"High\")\n",
    "    .otherwise(\"Low\")\n",
    ")\n",
    "\n",
    "# Mostrar el DataFrame con la nueva columna\n",
    "print(\"DataFrame con columna salary_category:\")\n",
    "enriched_employees_df.printSchema()\n",
    "enriched_employees_df.show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Filter and Group (20 points):\n",
    "Create two new data frames: one that filters employees with a “High” salary and another that filters employees with a “Low” salary.\n",
    "\n",
    "Calculate the average salary per department for the two newly created data frames, which contain the salaries of employees categorized as “High” and “Low.”  Resulting data frame for this transformation should contain only department_name and avg_salary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Promedio de salarios ALTOS por departamento:\n",
      "+-------------------------------------------+------------------+\n",
      "|department_name                            |avg_salary        |\n",
      "+-------------------------------------------+------------------+\n",
      "|Corporate Strategy and Business Development|102741.38324414717|\n",
      "|Sales and Marketing                        |100839.65275449108|\n",
      "|Data Engineering                           |101626.29492163012|\n",
      "+-------------------------------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "\n",
      "Promedio de salarios BAJOS por departamento:\n",
      "+-------------------------------------------+------------------+\n",
      "|department_name                            |avg_salary        |\n",
      "+-------------------------------------------+------------------+\n",
      "|Corporate Strategy and Business Development|41590.741833333326|\n",
      "|Sales and Marketing                        |41150.40277777778 |\n",
      "|Data Engineering                           |41358.50794117647 |\n",
      "+-------------------------------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "high_salary_df = enriched_employees_df.filter(col(\"salary_category\") == \"High\")\n",
    "low_salary_df = enriched_employees_df.filter(col(\"salary_category\") == \"Low\")\n",
    "\n",
    "\n",
    "high_salary_avg_by_dept = high_salary_df.groupBy(\"department_name\") \\\n",
    "    .agg(avg(\"salary\").alias(\"avg_salary\")) \\\n",
    "    .select(\"department_name\", \"avg_salary\")\n",
    "\n",
    "\n",
    "low_salary_avg_by_dept = low_salary_df.groupBy(\"department_name\") \\\n",
    "    .agg(avg(\"salary\").alias(\"avg_salary\")) \\\n",
    "    .select(\"department_name\", \"avg_salary\")\n",
    "\n",
    "\n",
    "print(\"\\nPromedio de salarios ALTOS por departamento:\")\n",
    "high_salary_avg_by_dept.show(3, truncate=False)\n",
    "\n",
    "\n",
    "print(\"\\nPromedio de salarios BAJOS por departamento:\")\n",
    "low_salary_avg_by_dept.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Sort (10 points):\n",
    "Find the Top 5 employees with highest salaries from employees categorized as “High”\n",
    "Find the Top 5 employees with highest salaries from employees categorized as “Low”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------------------------------+\n",
      "|name     |salary   |department_name                            |\n",
      "+---------+---------+-------------------------------------------+\n",
      "|Gabriella|149989.73|Human Resources                            |\n",
      "|Katherine|149979.3 |Human Resources                            |\n",
      "|Ryan     |149963.1 |Corporate Strategy and Business Development|\n",
      "|Caitlyn  |149956.54|Legal                                      |\n",
      "|Mark     |149915.56|Legal                                      |\n",
      "+---------+---------+-------------------------------------------+\n",
      "\n",
      "+-----+--------+-------------------------------------------+\n",
      "|name |salary  |department_name                            |\n",
      "+-----+--------+-------------------------------------------+\n",
      "|Linda|54993.53|Corporate Strategy and Business Development|\n",
      "|Tammy|54991.71|Data Engineering                           |\n",
      "|Aaron|54989.45|Finance and Accounting                     |\n",
      "|Craig|54945.2 |Human Resources                            |\n",
      "|Aaron|54937.3 |Customer Service                           |\n",
      "+-----+--------+-------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top5_high_salary = high_salary_df.select(\"name\", \"salary\", \"department_name\") \\\n",
    "    .orderBy(col(\"salary\").desc()) \\\n",
    "    .limit(5)\n",
    "\n",
    "\n",
    "top5_low_salary = low_salary_df.select(\"name\", \"salary\", \"department_name\") \\\n",
    "    .orderBy(col(\"salary\").desc()) \\\n",
    "    .limit(5)\n",
    "\n",
    "top5_high_salary.show(truncate=False)\n",
    "top5_low_salary.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Find the number of employees with more years in the company (15 points).\n",
    "Compute a new column with the years in company for each employee\n",
    "Find the list of employees with more years in company and count them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame con años en la empresa:\n",
      "+---------+----------+----------------+\n",
      "|     name| hire_date|years_in_company|\n",
      "+---------+----------+----------------+\n",
      "|  Caitlyn|2002-06-10|              23|\n",
      "|   Rachel|2009-07-01|              16|\n",
      "|   Carrie|1998-12-10|              27|\n",
      "|    Renee|1995-03-17|              30|\n",
      "|Gabriella|1995-02-09|              30|\n",
      "|  Kristen|2010-11-15|              15|\n",
      "| Jonathan|2012-06-30|              13|\n",
      "| Michelle|2005-10-30|              20|\n",
      "| Michelle|1991-07-10|              34|\n",
      "|     Lisa|2016-03-25|               9|\n",
      "+---------+----------+----------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "El máximo de años en la empresa es: 37\n",
      "\n",
      "Hay 88 empleados con 37 años en la empresa (los más antiguos):\n",
      "+--------+----------+----------------+------------------------+\n",
      "|name    |hire_date |years_in_company|department_name         |\n",
      "+--------+----------+----------------+------------------------+\n",
      "|Ana     |1988-12-31|37              |Data Engineering        |\n",
      "|Seth    |1988-08-29|37              |Human Resources         |\n",
      "|Megan   |1988-04-03|37              |Legal                   |\n",
      "|Sarah   |1988-04-14|37              |Sales and Marketing     |\n",
      "|Mark    |1988-11-20|37              |Sales and Marketing     |\n",
      "|Luke    |1988-07-12|37              |Operations              |\n",
      "|Carrie  |1988-06-28|37              |Data Engineering        |\n",
      "|James   |1988-10-06|37              |Finance and Accounting  |\n",
      "|Brandy  |1988-03-17|37              |Legal                   |\n",
      "|Jonathan|1988-07-26|37              |Research and Development|\n",
      "|Jorge   |1988-06-19|37              |Customer Service        |\n",
      "|William |1988-12-16|37              |Legal                   |\n",
      "|Tristan |1988-04-07|37              |Operations              |\n",
      "|Tammy   |1988-06-27|37              |Data Science            |\n",
      "|Raymond |1988-07-28|37              |Data Engineering        |\n",
      "|Rachel  |1988-06-08|37              |Finance and Accounting  |\n",
      "|Tristan |1988-05-05|37              |Finance and Accounting  |\n",
      "|Cheryl  |1988-08-31|37              |Operations              |\n",
      "|Amy     |1988-04-25|37              |Customer Service        |\n",
      "|Jennifer|1988-12-18|37              |Finance and Accounting  |\n",
      "+--------+----------+----------------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_date, datediff, col, lit, year\n",
    "\n",
    "employees_with_years = enriched_employees_df.withColumn(\n",
    "    \"years_in_company\",\n",
    "    year(current_date()) - year(col(\"hire_date\"))\n",
    ")\n",
    "\n",
    "\n",
    "print(\"DataFrame con años en la empresa:\")\n",
    "employees_with_years.select(\"name\", \"hire_date\", \"years_in_company\").show(10)\n",
    "\n",
    "\n",
    "max_years = employees_with_years.agg({\"years_in_company\": \"max\"}).collect()[0][0]\n",
    "print(f\"El máximo de años en la empresa es: {max_years}\")\n",
    "\n",
    "\n",
    "most_senior_employees = employees_with_years.filter(col(\"years_in_company\") == max_years)\n",
    "\n",
    "\n",
    "senior_count = most_senior_employees.count()\n",
    "\n",
    "\n",
    "print(f\"\\nHay {senior_count} empleados con {max_years} años en la empresa (los más antiguos):\")\n",
    "most_senior_employees.select(\"name\", \"hire_date\", \"years_in_company\", \"department_name\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the SparkContext\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
