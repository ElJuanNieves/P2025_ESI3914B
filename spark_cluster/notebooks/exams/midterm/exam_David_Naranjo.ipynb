{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../labs/img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "### <center> **Procesamiento de Datos Masivos** </center>\n",
    "---\n",
    "### <center> **Primavera 2025** </center>\n",
    "---\n",
    "**Primer Examen**\n",
    "\n",
    "**Fecha**: 14 de Marzo del 2025\n",
    "\n",
    "**Nombre del estudiante**:David Abraham Naranjo Salgado\n",
    "\n",
    "**Professor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SparkSQL-Exam-1-David-Naranjo\") \\\n",
    "    .master(\"spark://a343afeb5c7a:7077\") \\\n",
    "    .config(\"spark.ui.port\",\"4040\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import team_name.spark_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+-------------+\n",
      "|department_id|     department_name|     location|\n",
      "+-------------+--------------------+-------------+\n",
      "|          101|     Human Resources|    San Diego|\n",
      "|          102|Finance and Accou...|     New York|\n",
      "|          103| Sales and Marketing|      Chicago|\n",
      "|          104|    Data Engineering|      Zapopan|\n",
      "|          105|        Data Science|      Seattle|\n",
      "|          106|          Operations|       London|\n",
      "|          107|               Legal|      Chicago|\n",
      "|          108|Research and Deve...| Philadelphia|\n",
      "|          109|    Customer Service|San Francisco|\n",
      "|          110|Corporate Strateg...|  Los Angeles|\n",
      "+-------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "importlib.reload(team_name.spark_utils)\n",
    "\n",
    "columns_info = [ (\"department_id\", \"string\"),\n",
    "                (\"department_name\", \"string\"),\n",
    "                (\"location\", \"string\")]\n",
    "\n",
    "schema = team_name.spark_utils.SparkUtils.generate_schema(columns_info)\n",
    "\n",
    "departments_df = spark \\\n",
    "                .read \\\n",
    "                .schema(schema) \\\n",
    "                .option(\"header\", \"true\") \\\n",
    "                .csv(\"/home/jovyan/notebooks/data/departments.csv\")\n",
    "                \n",
    "departments_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|employee_id|       employee_info|\n",
      "+-----------+--------------------+\n",
      "|          1|{'name': 'Caitlyn...|\n",
      "|          2|{'name': 'Rachel'...|\n",
      "|          3|{'name': 'Carrie'...|\n",
      "|          4|{'name': 'Renee',...|\n",
      "|          5|{'name': 'Gabriel...|\n",
      "|          6|{'name': 'Kristen...|\n",
      "|          7|{'name': 'Jonatha...|\n",
      "|          8|{'name': 'Michell...|\n",
      "|          9|{'name': 'Michell...|\n",
      "|         10|{'name': 'Lisa', ...|\n",
      "+-----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "importlib.reload(team_name.spark_utils)\n",
    "\n",
    "columns_info = [ (\"employee_id\", \"string\"),\n",
    "                (\"employee_info\", \"string\")]\n",
    "\n",
    "schema = team_name.spark_utils.SparkUtils.generate_schema(columns_info)\n",
    "\n",
    "employee_df = spark \\\n",
    "                .read \\\n",
    "                .schema(schema) \\\n",
    "                .option(\"header\", \"true\") \\\n",
    "                .csv(\"/home/jovyan/notebooks/data/employees.csv\")\n",
    "                \n",
    "employee_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------------+---------+----------+\n",
      "|employee_id|     name|department_id|   salary| hire_date|\n",
      "+-----------+---------+-------------+---------+----------+\n",
      "|          1|  Caitlyn|          103|115959.78|2002-06-10|\n",
      "|          2|   Rachel|          104|100820.16|2009-07-01|\n",
      "|          3|   Carrie|          105|114421.44|1998-12-10|\n",
      "|          4|    Renee|          104| 54688.13|1995-03-17|\n",
      "|          5|Gabriella|          109|106267.03|1995-02-09|\n",
      "|          6|  Kristen|          101| 88237.54|2010-11-15|\n",
      "|          7| Jonathan|          102| 39323.42|2012-06-30|\n",
      "|          8| Michelle|          101| 64262.85|2005-10-30|\n",
      "|          9| Michelle|          105|103521.88|1991-07-10|\n",
      "|         10|     Lisa|          110| 55435.93|2016-03-25|\n",
      "+-----------+---------+-------------+---------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "employee_info_schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"department_id\", IntegerType(), True),\n",
    "    StructField(\"salary\", DoubleType(), True),\n",
    "    StructField(\"hire_date\", DateType(), True)\n",
    "])\n",
    "\n",
    "employee_df_parsed = employee_df.withColumn(\"employee_info_parsed\", from_json(col(\"employee_info\"), employee_info_schema))\n",
    "\n",
    "employee_df_selected = employee_df_parsed.select(\n",
    "    \"employee_id\",\n",
    "    \"employee_info_parsed.name\",\n",
    "    \"employee_info_parsed.department_id\",\n",
    "    \"employee_info_parsed.salary\",\n",
    "    \"employee_info_parsed.hire_date\"\n",
    ")\n",
    "\n",
    "employee_df_selected.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------------+---------+----------+-------------+-------------------+-------------+\n",
      "|employee_id|     name|department_id|   salary| hire_date|department_id|    department_name|     location|\n",
      "+-----------+---------+-------------+---------+----------+-------------+-------------------+-------------+\n",
      "|          1|  Caitlyn|          103|115959.78|2002-06-10|          103|Sales and Marketing|      Chicago|\n",
      "|          2|   Rachel|          104|100820.16|2009-07-01|          104|   Data Engineering|      Zapopan|\n",
      "|          3|   Carrie|          105|114421.44|1998-12-10|          105|       Data Science|      Seattle|\n",
      "|          4|    Renee|          104| 54688.13|1995-03-17|          104|   Data Engineering|      Zapopan|\n",
      "|          5|Gabriella|          109|106267.03|1995-02-09|          109|   Customer Service|San Francisco|\n",
      "+-----------+---------+-------------+---------+----------+-------------+-------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_combined_df = employee_df_selected.join(\n",
    "    departments_df, \n",
    "    employee_df_selected.department_id == departments_df.department_id,\n",
    "    \"inner\"\n",
    ")\n",
    "employee_combined_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------------+---------+----------+-------------+-------------------+-------------+---------------+\n",
      "|employee_id|     name|department_id|   salary| hire_date|department_id|    department_name|     location|salary_category|\n",
      "+-----------+---------+-------------+---------+----------+-------------+-------------------+-------------+---------------+\n",
      "|          1|  Caitlyn|          103|115959.78|2002-06-10|          103|Sales and Marketing|      Chicago|           High|\n",
      "|          2|   Rachel|          104|100820.16|2009-07-01|          104|   Data Engineering|      Zapopan|           High|\n",
      "|          3|   Carrie|          105|114421.44|1998-12-10|          105|       Data Science|      Seattle|           High|\n",
      "|          4|    Renee|          104| 54688.13|1995-03-17|          104|   Data Engineering|      Zapopan|            Low|\n",
      "|          5|Gabriella|          109|106267.03|1995-02-09|          109|   Customer Service|San Francisco|           High|\n",
      "+-----------+---------+-------------+---------+----------+-------------+-------------------+-------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "employee_combined_df = employee_combined_df.withColumn(\n",
    "    \"salary_category\",\n",
    "    when(col(\"salary\") >= 55000, \"High\").otherwise(\"Low\")\n",
    ")\n",
    "\n",
    "employee_combined_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------------+---------+----------+-------------+-------------------+-------------+---------------+\n",
      "|employee_id|     name|department_id|   salary| hire_date|department_id|    department_name|     location|salary_category|\n",
      "+-----------+---------+-------------+---------+----------+-------------+-------------------+-------------+---------------+\n",
      "|          1|  Caitlyn|          103|115959.78|2002-06-10|          103|Sales and Marketing|      Chicago|           High|\n",
      "|          2|   Rachel|          104|100820.16|2009-07-01|          104|   Data Engineering|      Zapopan|           High|\n",
      "|          3|   Carrie|          105|114421.44|1998-12-10|          105|       Data Science|      Seattle|           High|\n",
      "|          5|Gabriella|          109|106267.03|1995-02-09|          109|   Customer Service|San Francisco|           High|\n",
      "|          6|  Kristen|          101| 88237.54|2010-11-15|          101|    Human Resources|    San Diego|           High|\n",
      "+-----------+---------+-------------+---------+----------+-------------+-------------------+-------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "high_salary_df = employee_combined_df.filter(\n",
    "    col(\"salary_category\") == \"High\"\n",
    ")\n",
    "high_salary_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+-------------+--------+----------+-------------+--------------------+-------------+---------------+\n",
      "|employee_id|    name|department_id|  salary| hire_date|department_id|     department_name|     location|salary_category|\n",
      "+-----------+--------+-------------+--------+----------+-------------+--------------------+-------------+---------------+\n",
      "|          4|   Renee|          104|54688.13|1995-03-17|          104|    Data Engineering|      Zapopan|            Low|\n",
      "|          7|Jonathan|          102|39323.42|2012-06-30|          102|Finance and Accou...|     New York|            Low|\n",
      "|         13|    Lisa|          104|36032.49|2019-05-16|          104|    Data Engineering|      Zapopan|            Low|\n",
      "|         26|    John|          109|44836.57|2004-11-13|          109|    Customer Service|San Francisco|            Low|\n",
      "|         38|  Rachel|          109|43269.85|1992-07-13|          109|    Customer Service|San Francisco|            Low|\n",
      "+-----------+--------+-------------+--------+----------+-------------+--------------------+-------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "low_salary_df = employee_combined_df.filter(\n",
    "    col(\"salary_category\") == \"Low\"\n",
    ")\n",
    "low_salary_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|     department_name|        avg_salary|\n",
      "+--------------------+------------------+\n",
      "|Corporate Strateg...|102741.38324414717|\n",
      "| Sales and Marketing|100839.65275449108|\n",
      "|    Data Engineering|101626.29492163012|\n",
      "|Research and Deve...|  98714.3003086419|\n",
      "|Finance and Accou...|100731.07877887784|\n",
      "|    Customer Service|101585.01600000002|\n",
      "|               Legal|  99366.3129102167|\n",
      "|        Data Science|101903.63710344829|\n",
      "|          Operations|100169.65621722837|\n",
      "|     Human Resources|104999.43191489363|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "high_salary_avg = high_salary_df.groupBy(\"department_name\") \\\n",
    "    .agg(avg(\"salary\").alias(\"avg_salary\"))\n",
    "high_salary_avg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|     department_name|        avg_salary|\n",
      "+--------------------+------------------+\n",
      "|Corporate Strateg...|41590.741833333326|\n",
      "| Sales and Marketing| 41150.40277777778|\n",
      "|    Data Engineering| 41358.50794117647|\n",
      "|Finance and Accou...|42740.952888888874|\n",
      "|Research and Deve...| 41426.43521126761|\n",
      "|    Customer Service|42644.472021276604|\n",
      "|               Legal| 41160.26616438357|\n",
      "|        Data Science| 41974.18958333334|\n",
      "|          Operations|40646.100705882345|\n",
      "|     Human Resources| 41751.64784810126|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "low_salary_avg = low_salary_df.groupBy(\"department_name\") \\\n",
    "    .agg(avg(\"salary\").alias(\"avg_salary\"))\n",
    "low_salary_avg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------------+---------+----------+-------------+--------------------+-----------+---------------+\n",
      "|employee_id|     name|department_id|   salary| hire_date|department_id|     department_name|   location|salary_category|\n",
      "+-----------+---------+-------------+---------+----------+-------------+--------------------+-----------+---------------+\n",
      "|       1778|Gabriella|          101|149989.73|2018-09-14|          101|     Human Resources|  San Diego|           High|\n",
      "|       3621|Katherine|          101| 149979.3|2017-07-26|          101|     Human Resources|  San Diego|           High|\n",
      "|        346|     Ryan|          110| 149963.1|1990-07-03|          110|Corporate Strateg...|Los Angeles|           High|\n",
      "|       3807|  Caitlyn|          107|149956.54|2000-07-27|          107|               Legal|    Chicago|           High|\n",
      "|       3050|     Mark|          107|149915.56|2007-11-06|          107|               Legal|    Chicago|           High|\n",
      "+-----------+---------+-------------+---------+----------+-------------+--------------------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_high_salary= high_salary_df \\\n",
    "    .orderBy(col(\"salary\").desc()) \\\n",
    "    .limit(5)\n",
    "top_high_salary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+-------------+--------+----------+-------------+--------------------+-------------+---------------+\n",
      "|employee_id| name|department_id|  salary| hire_date|department_id|     department_name|     location|salary_category|\n",
      "+-----------+-----+-------------+--------+----------+-------------+--------------------+-------------+---------------+\n",
      "|       3472|Linda|          110|54993.53|2017-01-15|          110|Corporate Strateg...|  Los Angeles|            Low|\n",
      "|       2545|Tammy|          104|54991.71|2004-12-07|          104|    Data Engineering|      Zapopan|            Low|\n",
      "|        382|Aaron|          102|54989.45|2011-03-20|          102|Finance and Accou...|     New York|            Low|\n",
      "|       2153|Craig|          101| 54945.2|2016-04-24|          101|     Human Resources|    San Diego|            Low|\n",
      "|       3024|Aaron|          109| 54937.3|1994-06-25|          109|    Customer Service|San Francisco|            Low|\n",
      "+-----------+-----+-------------+--------+----------+-------------+--------------------+-------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_low_salary = low_salary_df \\\n",
    "    .orderBy(col(\"salary\").desc()) \\\n",
    "    .limit(5)\n",
    "top_low_salary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_date, datediff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------------+---------+----------+----------------+\n",
      "|employee_id|     name|department_id|   salary| hire_date|years_in_company|\n",
      "+-----------+---------+-------------+---------+----------+----------------+\n",
      "|          1|  Caitlyn|          103|115959.78|2002-06-10|              22|\n",
      "|          2|   Rachel|          104|100820.16|2009-07-01|              15|\n",
      "|          3|   Carrie|          105|114421.44|1998-12-10|              26|\n",
      "|          4|    Renee|          104| 54688.13|1995-03-17|              30|\n",
      "|          5|Gabriella|          109|106267.03|1995-02-09|              30|\n",
      "+-----------+---------+-------------+---------+----------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_df_with_years = employee_df_selected.withColumn(\n",
    "    \"years_in_company\",\n",
    "    (datediff(current_date(), col(\"hire_date\")) / 365).cast(\"integer\")\n",
    ")\n",
    "employee_df_with_years.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3225\n"
     ]
    }
   ],
   "source": [
    "employees_more_than_5_years = employee_df_with_years.filter(col(\"years_in_company\") > 5)\n",
    "num_employees_more_than_5_years = employees_more_than_5_years.count()\n",
    "print(num_employees_more_than_5_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
