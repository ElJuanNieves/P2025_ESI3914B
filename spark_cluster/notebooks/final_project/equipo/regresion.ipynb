{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../labs/img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> **Procesamiento de Datos Masivos** </center>\n",
    "---\n",
    "### <center> **Primavera 2025** </center>\n",
    "---\n",
    "### <center> **Ejemplos de Aprendizaje Automático (Machine Learning): Logistic Regression** </center>\n",
    "\n",
    "---\n",
    "**Profesor**: Dr. Pablo Camarillo Ramirez\n",
    "\n",
    "**Integrantes**:\n",
    "- Lorena Ruelas Gaytán\n",
    "- Yael Alejandro Rodríguez Barreto\n",
    "- Ximena Isaac Horta\n",
    "- Alberto Renteria Camacho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creacion de la conexión con el cluster de spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/29 00:25:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MLSpark-Logistic-Regression\") \\\n",
    "    .master(\"spark://e3b046ba856a:7077\") \\\n",
    "    .config(\"spark.ui.port\",\"4040\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+-----+---------+-------+----------+\n",
      "|male| age|education|currentSmoker|cigsPerDay|BPMeds|prevalentStroke|prevalentHyp|diabetes|totChol|sysBP|diaBP|  BMI|heartRate|glucose|TenYearCHD|\n",
      "+----+----+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+-----+---------+-------+----------+\n",
      "| 1.0|39.0|      4.0|          0.0|       0.0|   0.0|            0.0|         0.0|     0.0|  195.0|106.0| 70.0|26.97|     80.0|   77.0|       0.0|\n",
      "| 0.0|46.0|      2.0|          0.0|       0.0|   0.0|            0.0|         0.0|     0.0|  250.0|121.0| 81.0|28.73|     95.0|   76.0|       0.0|\n",
      "| 1.0|48.0|      1.0|          1.0|      20.0|   0.0|            0.0|         0.0|     0.0|  245.0|127.5| 80.0|25.34|     75.0|   70.0|       0.0|\n",
      "| 0.0|61.0|      3.0|          1.0|      30.0|   0.0|            0.0|         1.0|     0.0|  225.0|150.0| 95.0|28.58|     65.0|  103.0|       1.0|\n",
      "| 0.0|46.0|      3.0|          1.0|      23.0|   0.0|            0.0|         0.0|     0.0|  285.0|130.0| 84.0| 23.1|     85.0|   85.0|       0.0|\n",
      "| 0.0|43.0|      2.0|          0.0|       0.0|   0.0|            0.0|         1.0|     0.0|  228.0|180.0|110.0| 30.3|     77.0|   99.0|       0.0|\n",
      "| 0.0|63.0|      1.0|          0.0|       0.0|   0.0|            0.0|         0.0|     0.0|  205.0|138.0| 71.0|33.11|     60.0|   85.0|       1.0|\n",
      "| 0.0|45.0|      2.0|          1.0|      20.0|   0.0|            0.0|         0.0|     0.0|  313.0|100.0| 71.0|21.68|     79.0|   78.0|       0.0|\n",
      "| 1.0|52.0|      1.0|          0.0|       0.0|   0.0|            0.0|         1.0|     0.0|  260.0|141.5| 89.0|26.36|     76.0|   79.0|       0.0|\n",
      "| 1.0|43.0|      1.0|          1.0|      30.0|   0.0|            0.0|         1.0|     0.0|  225.0|162.0|107.0|23.61|     93.0|   88.0|       0.0|\n",
      "| 0.0|50.0|      1.0|          0.0|       0.0|   0.0|            0.0|         0.0|     0.0|  254.0|133.0| 76.0|22.91|     75.0|   76.0|       0.0|\n",
      "| 0.0|43.0|      2.0|          0.0|       0.0|   0.0|            0.0|         0.0|     0.0|  247.0|131.0| 88.0|27.64|     72.0|   61.0|       0.0|\n",
      "| 1.0|46.0|      1.0|          1.0|      15.0|   0.0|            0.0|         1.0|     0.0|  294.0|142.0| 94.0|26.31|     98.0|   64.0|       0.0|\n",
      "| 0.0|41.0|      3.0|          0.0|       0.0|   1.0|            0.0|         1.0|     0.0|  332.0|124.0| 88.0|31.31|     65.0|   84.0|       0.0|\n",
      "| 0.0|38.0|      2.0|          1.0|      20.0|   0.0|            0.0|         1.0|     0.0|  221.0|140.0| 90.0|21.35|     95.0|   70.0|       1.0|\n",
      "| 1.0|48.0|      3.0|          1.0|      10.0|   0.0|            0.0|         1.0|     0.0|  232.0|138.0| 90.0|22.37|     64.0|   72.0|       0.0|\n",
      "| 0.0|46.0|      2.0|          1.0|      20.0|   0.0|            0.0|         0.0|     0.0|  291.0|112.0| 78.0|23.38|     80.0|   89.0|       1.0|\n",
      "| 0.0|38.0|      2.0|          1.0|       5.0|   0.0|            0.0|         0.0|     0.0|  195.0|122.0| 84.5|23.24|     75.0|   78.0|       0.0|\n",
      "| 1.0|41.0|      2.0|          0.0|       0.0|   0.0|            0.0|         0.0|     0.0|  195.0|139.0| 88.0|26.88|     85.0|   65.0|       0.0|\n",
      "| 0.0|42.0|      2.0|          1.0|      30.0|   0.0|            0.0|         0.0|     0.0|  190.0|108.0| 70.5|21.59|     72.0|   85.0|       0.0|\n",
      "+----+----+---------+-------------+----------+------+---------------+------------+--------+-------+-----+-----+-----+---------+-------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from team_name.spark_utils import SparkUtils\n",
    "\n",
    "csv_path = \"/home/jovyan/notebooks/data/heartDisease/framingham.csv\"\n",
    "\n",
    "# Define schema for the DataFrame\n",
    "schema = SparkUtils.generate_schema([\n",
    "    (\"male\", \"float\"),\n",
    "    (\"age\", \"float\"),\n",
    "    (\"education\", \"float\"),\n",
    "    (\"currentSmoker\", \"float\"),\n",
    "    (\"cigsPerDay\", \"float\"),\n",
    "    (\"BPMeds\", \"float\"),\n",
    "    (\"prevalentStroke\", \"float\"),\n",
    "    (\"prevalentHyp\", \"float\"),\n",
    "    (\"diabetes\", \"float\"),\n",
    "    (\"totChol\", \"float\"),\n",
    "    (\"sysBP\", \"float\"),\n",
    "    (\"diaBP\", \"float\"),\n",
    "    (\"BMI\", \"float\"),\n",
    "    (\"heartRate\", \"float\"),\n",
    "    (\"glucose\", \"float\"),\n",
    "    (\"TenYearCHD\", \"float\")\n",
    "])\n",
    "\n",
    "\n",
    "# Convert list to a DataFrame\n",
    "df = spark.read.csv(csv_path, header=True, schema=schema)\n",
    "#df = spark.createDataFrame(data, schema)\n",
    "clean_df = df.dropna(how=\"any\")\n",
    "\n",
    "\n",
    "clean_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble the features into a single vector column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "df = clean_df.withColumnRenamed(\"TenYearCHD\", \"label\")\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"male\", \"age\", \"education\", \"currentSmoker\", \"cigsPerDay\", \"BPMeds\", \"prevalentStroke\", \"prevalentHyp\", \"diabetes\", \"totChol\", \"sysBP\", \"diaBP\", \"BMI\", \"heartRate\", \"glucose\"], outputCol=\"features\")\n",
    "data_with_features = assembler.transform(df).select(\"label\", \"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and test sets 80% training data and 20% testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data_with_features.randomSplit([0.8, 0.2], seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/29 00:25:50 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|[1.0,39.0,4.0,0.0...|\n",
      "|  0.0|(15,[1,2,9,10,11,...|\n",
      "|  0.0|[1.0,48.0,1.0,1.0...|\n",
      "|  1.0|[0.0,61.0,3.0,1.0...|\n",
      "|  0.0|[0.0,46.0,3.0,1.0...|\n",
      "|  0.0|[0.0,43.0,2.0,0.0...|\n",
      "|  1.0|(15,[1,2,9,10,11,...|\n",
      "|  0.0|[0.0,45.0,2.0,1.0...|\n",
      "|  0.0|[1.0,52.0,1.0,0.0...|\n",
      "|  0.0|[1.0,43.0,1.0,1.0...|\n",
      "|  0.0|(15,[1,2,9,10,11,...|\n",
      "|  0.0|(15,[1,2,9,10,11,...|\n",
      "|  0.0|[1.0,46.0,1.0,1.0...|\n",
      "|  0.0|[0.0,41.0,3.0,0.0...|\n",
      "|  1.0|[0.0,38.0,2.0,1.0...|\n",
      "|  0.0|[1.0,48.0,3.0,1.0...|\n",
      "|  1.0|[0.0,46.0,2.0,1.0...|\n",
      "|  0.0|[0.0,38.0,2.0,1.0...|\n",
      "|  0.0|[1.0,41.0,2.0,0.0...|\n",
      "|  0.0|[0.0,42.0,2.0,1.0...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Train set\n",
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(15,[1,2,9,10,11,...|\n",
      "|  0.0|(15,[1,2,9,10,11,...|\n",
      "|  0.0|(15,[1,2,9,10,11,...|\n",
      "|  0.0|(15,[1,2,9,10,11,...|\n",
      "|  0.0|(15,[1,2,9,10,11,...|\n",
      "|  0.0|(15,[1,2,9,10,11,...|\n",
      "|  0.0|(15,[1,2,9,10,11,...|\n",
      "|  0.0|(15,[1,2,9,10,11,...|\n",
      "|  0.0|(15,[1,2,9,10,11,...|\n",
      "|  0.0|(15,[1,2,9,10,11,...|\n",
      "|  0.0|(15,[1,2,9,10,11,...|\n",
      "|  0.0|(15,[1,2,9,10,11,...|\n",
      "|  0.0|(15,[1,2,9,10,11,...|\n",
      "|  0.0|(15,[1,2,9,10,11,...|\n",
      "|  0.0|(15,[1,2,9,10,11,...|\n",
      "|  0.0|(15,[1,2,9,10,11,...|\n",
      "|  0.0|(15,[1,2,9,10,11,...|\n",
      "|  0.0|(15,[1,2,9,10,11,...|\n",
      "|  0.0|(15,[1,2,9,10,11,...|\n",
      "|  0.0|(15,[1,2,9,10,11,...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Mostrar el dataset original\n",
    "print(\"Original Dataset\")\n",
    "data_with_features.show()\n",
    "\n",
    "# Mostrar el dataset de entrenamiento\n",
    "print(\"Train set\")\n",
    "train_data.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/29 00:26:29 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/04/29 00:26:29 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.4452204514191804,0.05502023704581662,-0.005981957123458555,0.13288946634661816,0.014078054908460756,0.20381267334203113,0.7378452494096633,0.17579813995375004,0.1054281636684124,0.002653991815607116,0.014925248129863155,0.0009680262107608984,0.0023616849292589105,-0.00455493418838834,0.008181404726362473]\n"
     ]
    }
   ],
   "source": [
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Print coefficients\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "\n",
    "# Display model summary\n",
    "training_summary = lr_model.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+\n",
      "|            features|prediction|         probability|\n",
      "+--------------------+----------+--------------------+\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.97307997228396...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.97544049852057...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.97668310812167...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.97511789633773...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96912089314642...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.97189152114976...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.97406166706312...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95604219650089...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.97631574844674...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95635794078057...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95994128841722...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95692612277421...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95943391997440...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95972432389436...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.97453960736890...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96336524517676...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.97332676188633...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96821175683698...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.94828180363594...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96270402894219...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95838937343836...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96214837624860...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95158707054019...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95891173943535...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96366793839155...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95955212818510...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96377959302166...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96520164201193...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96554948383925...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96143386780526...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96990051515996...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95344589914635...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.97024146926538...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96690062290862...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96407793786312...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96484513519186...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96514484108132...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96947060314764...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95181556148296...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.97147206647625...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96921170088192...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.97021582407421...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96010149300617...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95704533939652...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95323519221990...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96695503894339...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96442554484868...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.94780964558811...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95312428697743...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96146649754357...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95565619689481...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96430458542841...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95932842445584...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95993261775118...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96412970938209...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95637632641078...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.97028336561076...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96088563929473...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.93902270566234...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95142646758904...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95058020943847...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95125667041432...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.94722253492098...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.94695078351388...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.93999842374551...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95989467347717...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95551381786818...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.94720287647552...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.93835397407231...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.94515930138318...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.94450383409678...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.94835956349596...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.96356491114956...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.94529271290825...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.94692126039089...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.9137213973422,...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.93637793165983...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.91769193759855...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.90720239015311...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.93344526004561...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.89938025891867...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.86572050656076...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.94705050322285...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.94852049735991...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.87731763341132...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.90923850846553...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.95403248513133...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.93554958458441...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.90006632554096...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.92324736208288...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.91644137995873...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.92960706373458...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.93029327067335...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.89989886796415...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.93001942507089...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.94101225619476...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.91466250831140...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.91843051602358...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.92024661729428...|\n",
      "|(15,[1,2,9,10,11,...|       0.0|[0.90733571788996...|\n",
      "+--------------------+----------+--------------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the trained model to make predictions on the test data\n",
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "# Show predictions\n",
    "predictions.select(\"features\", \"prediction\", \"probability\").show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1:0.7942887623584284\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "f1 = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "print(f\"f1:{f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
