{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../../labs/img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> **Procesamiento de Datos Masivos** </center>\n",
    "---\n",
    "### <center> **Primavera 2025** </center>\n",
    "---\n",
    "### <center> **K means model** </center>\n",
    "\n",
    "---\n",
    "**Profesor**: Dr. Pablo Camarillo Ramirez\n",
    "\n",
    "**Integrantes**:\n",
    "- Lorena Ruelas Gaytán\n",
    "- Yael Alejandro Rodríguez Barreto\n",
    "- Ximena Isaac Horta\n",
    "- Alberto Renteria Camacho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPARK_ID = \"9aa900e9e1bd\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spark Conexion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MLSpark-K-means\") \\\n",
    "    .master(f\"spark://{SPARK_ID}:7077\") \\\n",
    "    .config(\"spark.ui.port\",\"4040\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraction of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 3020 Cols: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+--------------------+--------------------+--------------------+-------------+--------------+-----------+-----------+-----+\n",
      "|            tweet_id|user_id|           timestamp|                text|            hashtags|            mentions|retweet_count|favorite_count|reply_count|quote_count|views|\n",
      "+--------------------+-------+--------------------+--------------------+--------------------+--------------------+-------------+--------------+-----------+-----------+-----+\n",
      "|e9ff298e-0593-403...|      3|2024-09-18T06:19:...|Id nesciunt elige...|[\"quod\",\"voluptat...|        [\"zhidalgo\"]|          246|           892|         23|         17| 9767|\n",
      "|bd456ef7-2eed-425...|      3|2024-09-20T12:59:...|Praesentium sint ...|                  []|  [\"monteroarcelia\"]|          246|           610|          4|         17|16917|\n",
      "|2e9e17f3-1f8b-496...|      3|2025-01-30T01:07:...|Voluptates incidu...|      [\"neque\",\"in\"]|[\"barriosgeorgina...|          412|           109|         27|         17|17530|\n",
      "|7b9af6b7-770e-460...|      3|2024-05-14T20:30:...|A blanditiis repu...|              [\"ut\"]|[\"maria-josecolla...|          223|             8|          4|         27|17231|\n",
      "|da4de041-4e6e-4c2...|      3|2025-04-13T07:48:...|Itaque iure alias...|[\"quaerat\",\"maior...|[\"ivonne69\",\"mart...|          405|           202|          1|          9|17401|\n",
      "|d3d56b4b-fa7b-4df...|      3|2024-04-29T04:44:...|Commodi quaerat e...|        [\"nesciunt\"]|[\"carolina62\",\"ro...|          157|           210|          9|         28| 3020|\n",
      "|21501cec-faf1-415...|      3|2025-03-04T09:53:...|Suscipit at rem s...|                  []|        [\"eloisa19\"]|          311|            52|          1|          4| 7662|\n",
      "|1df17680-8f66-434...|      3|2024-10-29T09:52:...|Temporibus ipsam ...| [\"provident\",\"nam\"]|          [\"vcolon\"]|          483|            48|          6|         23|18600|\n",
      "|c13808f5-efe8-43b...|      3|2024-01-07T17:43:...|Mollitia voluptat...|[\"veniam\",\"impedit\"]|        [\"kbeltran\"]|          201|           785|         37|         23| 9216|\n",
      "|9858670d-1cfc-40b...|      3|2024-11-20T06:23:...|Beatae aspernatur...|                  []|[\"espartaolmos\",\"...|          285|           984|         26|         15| 3515|\n",
      "+--------------------+-------+--------------------+--------------------+--------------------+--------------------+-------------+--------------+-----------+-----------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- hashtags: string (nullable = true)\n",
      " |-- mentions: string (nullable = true)\n",
      " |-- retweet_count: integer (nullable = true)\n",
      " |-- favorite_count: integer (nullable = true)\n",
      " |-- reply_count: integer (nullable = true)\n",
      " |-- quote_count: integer (nullable = true)\n",
      " |-- views: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_path = \"/home/jovyan/notebooks/data/parquet/\"\n",
    "\n",
    "tweets_df = spark.read \\\n",
    "    .parquet(data_path)\n",
    "\n",
    "print(\"Rows:\", tweets_df.count(), \"Cols:\", len(tweets_df.columns))\n",
    "tweets_df.show(10)\n",
    "tweets_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble the features into a single vector column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "numeric_cols = [\n",
    "    \"retweet_count\", \"favorite_count\", \"reply_count\", \"quote_count\", \"views\"\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=numeric_cols, outputCol=\"features\")\n",
    "assembled_df = assembler.transform(tweets_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# KMeans at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "k_values = [2, 5, 10, 15, 20]\n",
    "kmeans = [KMeans().setK(k).setSeed(19) for k in k_values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [k.fit(assembled_df) for k in kmeans]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_models = \"/home/jovyan/notebooks/data/models/kmeans/\"\n",
    "#path_models = \"/home/jovyan/notebooks/final_project/equipo/models/kmeans/\"\n",
    "\n",
    "for m, k in zip(models, k_values):\n",
    "    m.save(f\"{path_models}modelk{k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# See results of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 ready\n",
      "Model 5 ready\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 10 ready\n",
      "Model 15 ready\n",
      "Model 20 ready\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeansModel\n",
    "\n",
    "path_models = \"/home/jovyan/notebooks/data/models/kmeans/\"\n",
    "#path_models = \"/home/jovyan/notebooks/final_project/equipo/models/kmeans/\"\n",
    "\n",
    "models = []\n",
    "k_values = [2, 5, 10, 15, 20]\n",
    "for i in k_values:\n",
    "    m = KMeansModel.load(f\"{path_models}modelk{i}\")\n",
    "    models.append(m)\n",
    "    print(\"Model\", i, \"ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+--------------------+--------------------+--------------------+-------------+--------------+-----------+-----------+-----+--------------------+----------+\n",
      "|            tweet_id|user_id|           timestamp|                text|            hashtags|            mentions|retweet_count|favorite_count|reply_count|quote_count|views|            features|prediction|\n",
      "+--------------------+-------+--------------------+--------------------+--------------------+--------------------+-------------+--------------+-----------+-----------+-----+--------------------+----------+\n",
      "|e9ff298e-0593-403...|      3|2024-09-18T06:19:...|Id nesciunt elige...|[\"quod\",\"voluptat...|        [\"zhidalgo\"]|          246|           892|         23|         17| 9767|[246.0,892.0,23.0...|         1|\n",
      "|bd456ef7-2eed-425...|      3|2024-09-20T12:59:...|Praesentium sint ...|                  []|  [\"monteroarcelia\"]|          246|           610|          4|         17|16917|[246.0,610.0,4.0,...|         0|\n",
      "|2e9e17f3-1f8b-496...|      3|2025-01-30T01:07:...|Voluptates incidu...|      [\"neque\",\"in\"]|[\"barriosgeorgina...|          412|           109|         27|         17|17530|[412.0,109.0,27.0...|         0|\n",
      "|7b9af6b7-770e-460...|      3|2024-05-14T20:30:...|A blanditiis repu...|              [\"ut\"]|[\"maria-josecolla...|          223|             8|          4|         27|17231|[223.0,8.0,4.0,27...|         0|\n",
      "|da4de041-4e6e-4c2...|      3|2025-04-13T07:48:...|Itaque iure alias...|[\"quaerat\",\"maior...|[\"ivonne69\",\"mart...|          405|           202|          1|          9|17401|[405.0,202.0,1.0,...|         0|\n",
      "|d3d56b4b-fa7b-4df...|      3|2024-04-29T04:44:...|Commodi quaerat e...|        [\"nesciunt\"]|[\"carolina62\",\"ro...|          157|           210|          9|         28| 3020|[157.0,210.0,9.0,...|         1|\n",
      "|21501cec-faf1-415...|      3|2025-03-04T09:53:...|Suscipit at rem s...|                  []|        [\"eloisa19\"]|          311|            52|          1|          4| 7662|[311.0,52.0,1.0,4...|         1|\n",
      "|1df17680-8f66-434...|      3|2024-10-29T09:52:...|Temporibus ipsam ...| [\"provident\",\"nam\"]|          [\"vcolon\"]|          483|            48|          6|         23|18600|[483.0,48.0,6.0,2...|         0|\n",
      "|c13808f5-efe8-43b...|      3|2024-01-07T17:43:...|Mollitia voluptat...|[\"veniam\",\"impedit\"]|        [\"kbeltran\"]|          201|           785|         37|         23| 9216|[201.0,785.0,37.0...|         1|\n",
      "|9858670d-1cfc-40b...|      3|2024-11-20T06:23:...|Beatae aspernatur...|                  []|[\"espartaolmos\",\"...|          285|           984|         26|         15| 3515|[285.0,984.0,26.0...|         1|\n",
      "|454e7684-1609-41b...|      3|2024-12-04T20:15:...|Vel tempora at ip...|[\"sapiente\",\"inve...|                  []|          430|           717|         49|         44|13857|[430.0,717.0,49.0...|         0|\n",
      "|24e916f2-7df9-4df...|      3|2024-12-26T08:04:...|Hic magnam offici...|[\"laudantium\",\"vo...|                  []|          494|           564|         26|         14|15490|[494.0,564.0,26.0...|         0|\n",
      "|5b2fbb91-7f13-46b...|      3|2024-12-25T00:22:...|Dolores minima nu...|[\"excepturi\",\"mol...|                  []|          117|           968|         89|         27| 5510|[117.0,968.0,89.0...|         1|\n",
      "|402e1aaf-2338-453...|      3|2024-02-06T18:24:...|Repellat explicab...|                  []|                  []|          422|           758|         86|          7| 8826|[422.0,758.0,86.0...|         1|\n",
      "|1aba248f-11ac-422...|      3|2024-12-26T23:58:...|Hic recusandae ea...|[\"deserunt\",\"quis...|[\"galarzaofelia\",...|          182|           711|         76|         44|12512|[182.0,711.0,76.0...|         0|\n",
      "|372b1528-d508-41a...|      3|2025-03-22T06:59:...|Dolores ratione s...|[\"perferendis\",\"n...|[\"gcardenas\",\"san...|          292|            67|         10|         49|11648|[292.0,67.0,10.0,...|         0|\n",
      "|d07568c1-b659-45b...|      3|2024-05-02T08:21:...|Fuga maiores prov...|            [\"quam\"]|                  []|            1|           260|         18|          2|12474|[1.0,260.0,18.0,2...|         0|\n",
      "|3b772b2a-3320-49f...|      3|2024-09-06T23:39:...|Libero architecto...|[\"eveniet\",\"offic...|[\"avilesleonor\",\"...|          111|           417|         59|         37| 4825|[111.0,417.0,59.0...|         1|\n",
      "|487ca918-f75d-464...|      3|2025-04-30T14:38:...|Laborum eos at cu...|         [\"tenetur\"]|    [\"ericcasanova\"]|          398|           729|         18|         12|12087|[398.0,729.0,18.0...|         0|\n",
      "|846b11fe-ef25-413...|      3|2025-01-29T03:14:...|Voluptatem debiti...|  [\"necessitatibus\"]|                  []|          151|           427|         63|          8|17411|[151.0,427.0,63.0...|         0|\n",
      "+--------------------+-------+--------------------+--------------------+--------------------+--------------------+-------------+--------------+-----------+-----------+-----+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = [model.transform(assembled_df) for model in models]\n",
    "predictions[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.                 (0 + 1) / 1]\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/spark-3.5.4-bin-hadoop3-scala2.13/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/spark-3.5.4-bin-hadoop3-scala2.13/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     p \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m)[j]\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdouble\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     18\u001b[0m df \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoalesce\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpath_models\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43mcsvwithk\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/spark-3.5.4-bin-hadoop3-scala2.13/python/pyspark/sql/readwriter.py:1864\u001b[0m, in \u001b[0;36mDataFrameWriter.csv\u001b[0;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode(mode)\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(\n\u001b[1;32m   1847\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[1;32m   1848\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1862\u001b[0m     lineSep\u001b[38;5;241m=\u001b[39mlineSep,\n\u001b[1;32m   1863\u001b[0m )\n\u001b[0;32m-> 1864\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/spark-3.5.4-bin-hadoop3-scala2.13/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/opt/conda/spark-3.5.4-bin-hadoop3-scala2.13/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/opt/conda/spark-3.5.4-bin-hadoop3-scala2.13/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mreadline()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, split, regexp_replace\n",
    "\n",
    "path_models = \"/home/jovyan/notebooks/data/csvs/\"\n",
    "#path_models = \"/home/jovyan/notebooks/final_project/equipo/models/kmeans/\"\n",
    "\n",
    "k_values = [2, 5, 10, 15, 20]\n",
    "for i, p in zip(k_values, predictions):\n",
    "\n",
    "    p = p.withColumn(\"features\", col(\"features\").cast(\"string\"))\n",
    "    p = p.withColumn(\"features\", regexp_replace(\"features\", r'^\\[|\\]$', ''))\n",
    "    p = p.withColumn(\"features\", split(col(\"features\"), \",\"))\n",
    "\n",
    "    num_features = len(p.select(\"features\").first()[0])\n",
    "\n",
    "    for j in range(num_features):\n",
    "        p = p.withColumn(f\"feature_{j}\", col(\"features\")[j].cast(\"double\"))\n",
    "\n",
    "    df = p.drop(\"features\")\n",
    "    df.coalesce(1).write.option(\"header\", \"true\").csv(f\"{path_models}csvwithk{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "for i in range(len(k_values)):\n",
    "    print(f\"\\n K values = {k_values[i]}\")\n",
    "    evaluator = ClusteringEvaluator()\n",
    "    silhouette = evaluator.evaluate(predictions[i])\n",
    "    print(f\"Silhouette score: {silhouette}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(k_values)):\n",
    "    print(f\"\\n K values = {k_values[i]}\")\n",
    "    print(\"Cluster Centers: \")\n",
    "    for center in models[i].clusterCenters():\n",
    "        print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
