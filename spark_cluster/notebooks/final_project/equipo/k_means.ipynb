{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../labs/img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> **Procesamiento de Datos Masivos** </center>\n",
    "---\n",
    "### <center> **Primavera 2025** </center>\n",
    "---\n",
    "### <center> **K means model** </center>\n",
    "\n",
    "---\n",
    "**Profesor**: Dr. Pablo Camarillo Ramirez\n",
    "\n",
    "**Integrantes**:\n",
    "- Lorena Ruelas Gaytán\n",
    "- Yael Alejandro Rodríguez Barreto\n",
    "- Ximena Isaac Horta\n",
    "- Alberto Renteria Camacho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPARK_ID = \"b37d873f80db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spark Conexion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/10 00:25:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MLSpark-K-means\") \\\n",
    "    .master(f\"spark://{SPARK_ID}:7077\") \\\n",
    "    .config(\"spark.ui.port\",\"4040\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraction of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 36 Cols: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+-------+---------+------+--------------------+-------------+--------------------+\n",
      "| key|               value|  topic|partition|offset|           timestamp|timestampType|           value_str|\n",
      "+----+--------------------+-------+---------+------+--------------------+-------------+--------------------+\n",
      "|NULL|[7B 22 74 77 65 6...|tweet-1|        0|    17|2025-05-10 00:22:...|            0|{\"tweet_id\": \"6ff...|\n",
      "|NULL|[7B 22 74 77 65 6...|tweet-2|        0|    17|2025-05-10 00:22:...|            0|{\"tweet_id\": \"dc4...|\n",
      "|NULL|[7B 22 74 77 65 6...|tweet-3|        0|    17|2025-05-10 00:22:...|            0|{\"tweet_id\": \"209...|\n",
      "|NULL|[7B 22 74 77 65 6...|tweet-4|        0|    17|2025-05-10 00:22:...|            0|{\"tweet_id\": \"f54...|\n",
      "|NULL|[7B 22 74 77 65 6...|tweet-4|        0|    11|2025-05-10 00:21:...|            0|{\"tweet_id\": \"d55...|\n",
      "|NULL|[7B 22 74 77 65 6...|tweet-4|        0|    12|2025-05-10 00:21:...|            0|{\"tweet_id\": \"6de...|\n",
      "|NULL|[7B 22 74 77 65 6...|tweet-4|        0|    13|2025-05-10 00:21:...|            0|{\"tweet_id\": \"92d...|\n",
      "|NULL|[7B 22 74 77 65 6...|tweet-4|        0|    14|2025-05-10 00:21:...|            0|{\"tweet_id\": \"497...|\n",
      "|NULL|[7B 22 74 77 65 6...|tweet-3|        0|    11|2025-05-10 00:21:...|            0|{\"tweet_id\": \"ac2...|\n",
      "|NULL|[7B 22 74 77 65 6...|tweet-3|        0|    12|2025-05-10 00:21:...|            0|{\"tweet_id\": \"433...|\n",
      "+----+--------------------+-------+---------+------+--------------------+-------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/home/jovyan/notebooks/data/parquet/\"\n",
    "\n",
    "raw_df = spark.read \\\n",
    "    .parquet(data_path)\n",
    "\n",
    "print(\"Rows:\", raw_df.count(), \"Cols:\", len(raw_df.columns))\n",
    "raw_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 36 Cols: 11\n",
      "root\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- hashtags: string (nullable = true)\n",
      " |-- mentions: string (nullable = true)\n",
      " |-- retweet_count: integer (nullable = true)\n",
      " |-- favorite_count: integer (nullable = true)\n",
      " |-- reply_count: integer (nullable = true)\n",
      " |-- quote_count: integer (nullable = true)\n",
      " |-- views: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+--------------------+--------------------+--------------------+-------------+--------------+-----------+-----------+-----+\n",
      "|            tweet_id|user_id|           timestamp|                text|            hashtags|            mentions|retweet_count|favorite_count|reply_count|quote_count|views|\n",
      "+--------------------+-------+--------------------+--------------------+--------------------+--------------------+-------------+--------------+-----------+-----------+-----+\n",
      "|6ff004dd-e045-4bd...|      1|2025-03-03T20:50:...|Dolor non magni d...|[\"pariatur\",\"repe...|    [\"fidelsantana\"]|          235|            71|          1|         24|11548|\n",
      "|dc41957c-3fb8-4df...|      2|2024-10-25T13:39:...|Quia necessitatib...|[\"facere\",\"delect...|                  []|          410|           312|         13|         41|14705|\n",
      "|2095e1ec-7fcf-4e9...|      3|2025-04-19T02:59:...|Fuga praesentium ...|[\"iure\",\"perspici...|       [\"mariano09\"]|          251|           710|         23|         45|16739|\n",
      "|f54c8423-9550-4b3...|      4|2024-09-08T21:14:...|Maiores tempora d...|[\"corporis\",\"erro...|        [\"carlos17\"]|          257|           270|         61|         50| 8549|\n",
      "|d554fb57-7147-436...|      4|2024-01-12T17:49:...|Eaque molestias e...|[\"voluptatibus\",\"...|[\"paola36\",\"estra...|          292|           791|         74|         42|10640|\n",
      "|6de70b41-bfc9-4cf...|      4|2025-02-09T11:45:...|Quaerat laborum e...|                  []|[\"jaquelineescoba...|          105|           387|         83|         13| 1990|\n",
      "|92d1ab5f-e59d-4df...|      4|2024-09-22T11:31:...|Molestiae hic inv...|                  []|      [\"reynaldo16\"]|          347|           283|          8|         22| 6371|\n",
      "|4972ce6b-327a-4fb...|      4|2024-01-03T09:41:...|Natus nemo soluta...|[\"explicabo\",\"dic...|      [\"fernando61\"]|          417|           257|         93|         19|16307|\n",
      "|ac267587-8ca0-42f...|      3|2024-06-14T10:59:...|Culpa ducimus sed...|           [\"natus\"]|                  []|           68|           125|         43|         10|14225|\n",
      "|433ce099-0cb0-4f1...|      3|2024-09-06T19:09:...|Consequuntur iste...|[\"reprehenderit\",...|                  []|          265|            64|         89|          3| 8090|\n",
      "+--------------------+-------+--------------------+--------------------+--------------------+--------------------+-------------+--------------+-----------+-----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from equipo.spark_utils import SparkUtils\n",
    "from pyspark.sql.functions import from_json\n",
    "\n",
    "headers = [\n",
    "        (\"tweet_id\", \"string\"),\n",
    "        (\"user_id\", \"integer\"),\n",
    "        (\"timestamp\", \"string\"),\n",
    "        (\"text\", \"string\"),\n",
    "        (\"hashtags\", \"string\"),\n",
    "        (\"mentions\", \"string\"),\n",
    "        (\"retweet_count\", \"integer\"),\n",
    "        (\"favorite_count\", \"integer\"),\n",
    "        (\"reply_count\", \"integer\"),\n",
    "        (\"quote_count\", \"integer\"),\n",
    "        (\"views\", \"integer\")\n",
    "]\n",
    "\n",
    "schema = SparkUtils.generate_schema([(head[0], head[1]) for head in headers])\n",
    "\n",
    "tweets_df = raw_df.select(from_json(raw_df.value_str, schema).alias(\"data\")).select(\"data.*\")\n",
    "\n",
    "print(\"Rows:\", tweets_df.count(), \"Cols:\", len(tweets_df.columns))\n",
    "tweets_df.printSchema()\n",
    "tweets_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble the features into a single vector column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "numeric_cols = [\n",
    "    \"retweet_count\", \"favorite_count\", \"reply_count\", \"quote_count\", \"views\"\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=numeric_cols, outputCol=\"features\")\n",
    "assembled_df = assembler.transform(tweets_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# KMeans at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "k_values = [2, 5, 10, 15, 20]\n",
    "kmeans = [KMeans().setK(k).setSeed(19) for k in k_values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "models = [k.fit(assembled_df) for k in kmeans]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "path_models = \"/home/jovyan/notebooks/data/models/kmeans/\"\n",
    "#path_models = \"/home/jovyan/notebooks/final_project/equipo/models/kmeans/\"\n",
    "\n",
    "for m, k in zip(models, k_values):\n",
    "    m.save(f\"{path_models}modelk{k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# See results of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 ready\n",
      "Model 5 ready\n",
      "Model 10 ready\n",
      "Model 15 ready\n",
      "Model 20 ready\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeansModel\n",
    "\n",
    "path_models = \"/home/jovyan/notebooks/data/models/\"\n",
    "#path_models = \"/home/jovyan/notebooks/final_project/equipo/models/kmeans/\"\n",
    "\n",
    "models = []\n",
    "for i in k_values:\n",
    "    m = KMeansModel.load(f\"{path_models}modelk{i}\")\n",
    "    models.append(m)\n",
    "    print(\"Model\", i, \"ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [model.transform(assembled_df) for model in models]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " K values = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score: 0.8489901992457758\n",
      "\n",
      " K values = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score: 0.6607459863802264\n",
      "\n",
      " K values = 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score: 0.6619176817316299\n",
      "\n",
      " K values = 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score: 0.5558191669077037\n",
      "\n",
      " K values = 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 374:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette score: 0.45331720143081367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "for i in range(len(k_values)):\n",
    "    print(f\"\\n K values = {k_values[i]}\")\n",
    "    evaluator = ClusteringEvaluator()\n",
    "    silhouette = evaluator.evaluate(predictions[i])\n",
    "    print(f\"Silhouette score: {silhouette}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " K values = 2\n",
      "Cluster Centers: \n",
      "[ 272.76923077  528.30769231   47.30769231   22.15384615 4379.76923077]\n",
      "[  266.7826087    518.30434783    43.30434783    28.56521739\n",
      " 15274.17391304]\n",
      "\n",
      " K values = 5\n",
      "Cluster Centers: \n",
      "[  231.71428571   390.57142857    61.42857143    28.42857143\n",
      " 10326.57142857]\n",
      "[  190.75   747.75    31.25    44.25 18890.75]\n",
      "[ 286.4  649.2   44.2   21.2 1458.6]\n",
      "[ 291.4  507.8   33.2   24.  4767.2]\n",
      "[  293.86666667   485.26666667    44.6           22.86666667\n",
      " 15284.33333333]\n",
      "\n",
      " K values = 10\n",
      "Cluster Centers: \n",
      "[ 251.    341.5    59.     21.   8044.75]\n",
      "[  265.5     472.       54.625    26.875 16337.5  ]\n",
      "[318.5 833.   44.   25.  411.5]\n",
      "[  263.5   431.     37.5    33.  11094. ]\n",
      "[ 267.5   435.5    51.75   26.25 2431.25]\n",
      "[  190.75   747.75    31.25    44.25 18890.75]\n",
      "[4.08000000e+02 7.43333333e+02 1.63333333e+01 7.00000000e+00\n",
      " 1.36586667e+04]\n",
      "[  265.     318.25    45.75    26.75 14397.25]\n",
      "[  219.    394.5    63.5    35.5 12145. ]\n",
      "[ 278.33333333  698.           28.           16.33333333 4736.66666667]\n",
      "\n",
      " K values = 15\n",
      "Cluster Centers: \n",
      "[  242.5    439.25    31.      33.   17151.75]\n",
      "[318.5 833.   44.   25.  411.5]\n",
      "[  292.   791.    74.    42. 10640.]\n",
      "[4.08000000e+02 7.43333333e+02 1.63333333e+01 7.00000000e+00\n",
      " 1.36586667e+04]\n",
      "[ 347.  283.    8.   22. 6371.]\n",
      "[  164.           699.            41.33333333    46.66666667\n",
      " 19207.33333333]\n",
      "[ 373.5  372.    51.    30.5 2919.5]\n",
      "[ 278.33333333  698.           28.           16.33333333 4736.66666667]\n",
      "[  224.33333333   286.66666667    42.66666667    31.66666667\n",
      " 11946.        ]\n",
      "[1.350e+02 7.490e+02 7.800e+01 9.000e+00 9.169e+03]\n",
      "[  237.           408.66666667    63.33333333    26.33333333\n",
      " 16213.66666667]\n",
      "[  265.     318.25    45.75    26.75 14397.25]\n",
      "[ 161.5  499.    52.5   22.  1943. ]\n",
      "[ 261.   167.    75.    26.5 8319.5]\n",
      "[  357.    843.5    62.     20.5 15696.5]\n",
      "\n",
      " K values = 20\n",
      "Cluster Centers: \n",
      "[2.7100e+02 8.9400e+02 1.0000e+00 3.7000e+01 1.7941e+04]\n",
      "[318.5 833.   44.   25.  411.5]\n",
      "[  224.33333333   286.66666667    42.66666667    31.66666667\n",
      " 11946.        ]\n",
      "[4.80500e+02 6.72000e+02 1.00000e+01 8.00000e+00 1.35215e+04]\n",
      "[ 347.  283.    8.   22. 6371.]\n",
      "[  265.    666.5    49.5    32.5 16544.5]\n",
      "[ 267.5   435.5    51.75   26.25 2431.25]\n",
      "[ 419.  671.   28.   39. 4812.]\n",
      "[1.350e+02 7.490e+02 7.800e+01 9.000e+00 9.169e+03]\n",
      "[  292.   791.    74.    42. 10640.]\n",
      "[  224.     76.5    50.     25.  16963.5]\n",
      "[4.1000e+02 3.1200e+02 1.3000e+01 4.1000e+01 1.4705e+04]\n",
      "[  216.    301.5    57.     29.5 16145.5]\n",
      "[ 261.   167.    75.    26.5 8319.5]\n",
      "[  164.           699.            41.33333333    46.66666667\n",
      " 19207.33333333]\n",
      "[8.000e+00 9.970e+02 1.700e+01 2.000e+00 5.247e+03]\n",
      "[1.36000e+02 2.00000e+02 3.65000e+01 1.25000e+01 1.43305e+04]\n",
      "[  357.    843.5    62.     20.5 15696.5]\n",
      "[  320.5   723.5    63.     23.  14078. ]\n",
      "[ 408.  426.   39.    8. 4151.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(k_values)):\n",
    "    print(f\"\\n K values = {k_values[i]}\")\n",
    "    print(\"Cluster Centers: \")\n",
    "    for center in models[i].clusterCenters():\n",
    "        print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
