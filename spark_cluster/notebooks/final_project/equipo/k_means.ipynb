{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../labs/img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> **Procesamiento de Datos Masivos** </center>\n",
    "---\n",
    "### <center> **Primavera 2025** </center>\n",
    "---\n",
    "### <center> **K means model** </center>\n",
    "\n",
    "---\n",
    "**Profesor**: Dr. Pablo Camarillo Ramirez\n",
    "\n",
    "**Integrantes**:\n",
    "- Lorena Ruelas Gaytán\n",
    "- Yael Alejandro Rodríguez Barreto\n",
    "- Ximena Isaac Horta\n",
    "- Alberto Renteria Camacho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPARK_ID = \"5af50e5e22eb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spark Conexion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MLSpark-K-means\") \\\n",
    "    .master(f\"spark://{SPARK_ID}:7077\") \\\n",
    "    .config(\"spark.ui.port\",\"4040\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraction of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 47 Cols: 11\n",
      "+--------------------+-------+--------------------+--------------------+--------------------+--------------------+-------------+--------------+-----------+-----------+-----+\n",
      "|            tweet_id|user_id|           timestamp|                text|            hashtags|            mentions|retweet_count|favorite_count|reply_count|quote_count|views|\n",
      "+--------------------+-------+--------------------+--------------------+--------------------+--------------------+-------------+--------------+-----------+-----------+-----+\n",
      "|53a34b7a-a612-442...|      1|2025-01-12T21:39:...|Voluptatum veniam...|[\"veritatis\",\"nes...|        [\"rafael92\"]|          190|           370|         94|          5| 5056|\n",
      "|74528c8a-2958-439...|      1|2024-02-06T17:35:...|Inventore non quo...|[\"amet\",\"at\",\"eli...|                  []|          107|           640|         31|         13| 4343|\n",
      "|5ac61920-5040-458...|      1|2024-12-02T04:29:...|Id magnam impedit...|         [\"impedit\"]|[\"humberto33\",\"fe...|          425|           754|         57|          0|16568|\n",
      "|b2467d4d-0f58-464...|      1|2024-02-11T06:58:...|Sed quae quaerat ...|[\"consectetur\",\"n...|       [\"mateotoro\"]|          199|           520|         24|         15| 6647|\n",
      "|ddb45fbb-a997-4f7...|      1|2024-12-26T16:28:...|Eum delectus prae...|     [\"non\",\"vitae\"]|                  []|          405|           115|         80|         47|19332|\n",
      "|c4624a1f-8c43-42f...|      1|2025-03-07T20:20:...|Amet officia natu...|       [\"sint\",\"et\"]|                  []|           17|           183|         60|          0| 6451|\n",
      "|3230339b-bb21-412...|      1|2024-08-13T11:31:...|Iure minus maiore...|                  []|[\"jose-emilio08\",...|           88|           802|         24|          3|14235|\n",
      "|d922b8a1-a739-482...|      1|2025-01-20T08:42:...|Nobis similique c...|   [\"error\",\"totam\"]|[\"daliaalcala\",\"a...|          357|           317|         20|          9| 4477|\n",
      "|7f2aa1af-a7b2-4c1...|      1|2024-04-08T22:09:...|Officia dolorem c...|            [\"vero\"]|      [\"patricio06\"]|          159|           166|         35|         26|13724|\n",
      "|13c9c503-1e88-48f...|      1|2024-12-28T16:48:...|Reiciendis mollit...|                  []|                  []|          499|           741|         49|          5| 1921|\n",
      "+--------------------+-------+--------------------+--------------------+--------------------+--------------------+-------------+--------------+-----------+-----------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "root\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- hashtags: string (nullable = true)\n",
      " |-- mentions: string (nullable = true)\n",
      " |-- retweet_count: integer (nullable = true)\n",
      " |-- favorite_count: integer (nullable = true)\n",
      " |-- reply_count: integer (nullable = true)\n",
      " |-- quote_count: integer (nullable = true)\n",
      " |-- views: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/home/jovyan/notebooks/data/parquet/\"\n",
    "\n",
    "tweets_df = spark.read \\\n",
    "    .parquet(data_path)\n",
    "\n",
    "print(\"Rows:\", tweets_df.count(), \"Cols:\", len(tweets_df.columns))\n",
    "tweets_df.show(10)\n",
    "tweets_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 392 Cols: 11\n",
      "root\n",
      " |-- tweet_id: string (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- timestamp: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- hashtags: string (nullable = true)\n",
      " |-- mentions: string (nullable = true)\n",
      " |-- retweet_count: integer (nullable = true)\n",
      " |-- favorite_count: integer (nullable = true)\n",
      " |-- reply_count: integer (nullable = true)\n",
      " |-- quote_count: integer (nullable = true)\n",
      " |-- views: integer (nullable = true)\n",
      "\n",
      "+--------------------+-------+--------------------+--------------------+--------------------+--------------------+-------------+--------------+-----------+-----------+-----+\n",
      "|            tweet_id|user_id|           timestamp|                text|            hashtags|            mentions|retweet_count|favorite_count|reply_count|quote_count|views|\n",
      "+--------------------+-------+--------------------+--------------------+--------------------+--------------------+-------------+--------------+-----------+-----------+-----+\n",
      "|63ba5bd7-c4c4-454...|      1|2024-01-23T05:50:...|Veritatis dolorem...|[\"voluptates\",\"ve...|[\"teranpamela\",\"e...|          461|           428|         28|         25| 4023|\n",
      "|23bff5f4-2ee9-4e8...|      4|2024-10-29T17:34:...|Quae animi quidem...|     [\"accusantium\"]|[\"rafael61\",\"hele...|          307|           715|         72|         28| 8853|\n",
      "|505b3625-349f-4d9...|      1|2024-10-31T06:52:...|Vero incidunt sae...|[\"voluptatibus\",\"...|      [\"gregorio89\"]|           89|           833|         55|         49| 8528|\n",
      "|6bff024c-f2d7-470...|      3|2024-04-15T19:06:...|Sint facere perfe...|[\"est\",\"dolorum\",...|                  []|          180|           482|         36|         12|17494|\n",
      "|2f4854d9-97c6-46c...|      3|2024-10-16T20:05:...|Illo doloribus di...|[\"odio\",\"aperiam\"...|[\"inesolmos\",\"lur...|          495|           915|         70|          3|17228|\n",
      "|c02d105a-5e4b-46e...|      3|2024-10-01T02:43:...|Saepe eaque dolor...|[\"nemo\",\"recusand...|[\"guillermo21\",\"f...|           21|           564|          0|          5|16876|\n",
      "|026a60e2-6145-41f...|      3|2024-08-31T21:44:...|Tempora nulla ita...|           [\"dicta\"]|                  []|          370|           737|         18|         21|11497|\n",
      "|5109d500-4153-45f...|      4|2024-05-16T20:21:...|Velit itaque elig...|              [\"ut\"]|[\"menendezgabriel...|          251|           558|         17|         29| 1895|\n",
      "|7b03abc9-c21a-437...|      1|2024-09-28T20:09:...|Optio hic aperiam...|  [\"quod\",\"tempore\"]|[\"rhurtado\",\"merc...|           67|           550|         16|         34| 3427|\n",
      "|a9e46fb5-29df-44b...|      1|2025-03-27T19:58:...|Voluptatibus exer...|                  []|          [\"adan22\"]|           49|           931|         24|         37| 1334|\n",
      "+--------------------+-------+--------------------+--------------------+--------------------+--------------------+-------------+--------------+-----------+-----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from equipo.spark_utils import SparkUtils\n",
    "from pyspark.sql.functions import from_json\n",
    "\n",
    "headers = [\n",
    "        (\"tweet_id\", \"string\"),\n",
    "        (\"user_id\", \"integer\"),\n",
    "        (\"timestamp\", \"string\"),\n",
    "        (\"text\", \"string\"),\n",
    "        (\"hashtags\", \"string\"),\n",
    "        (\"mentions\", \"string\"),\n",
    "        (\"retweet_count\", \"integer\"),\n",
    "        (\"favorite_count\", \"integer\"),\n",
    "        (\"reply_count\", \"integer\"),\n",
    "        (\"quote_count\", \"integer\"),\n",
    "        (\"views\", \"integer\")\n",
    "]\n",
    "\n",
    "schema = SparkUtils.generate_schema([(head[0], head[1]) for head in headers])\n",
    "\n",
    "tweets_df = raw_df.select(from_json(raw_df.value_str, schema).alias(\"data\")).select(\"data.*\")\n",
    "\n",
    "print(\"Rows:\", tweets_df.count(), \"Cols:\", len(tweets_df.columns))\n",
    "tweets_df.printSchema()\n",
    "tweets_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble the features into a single vector column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "numeric_cols = [\n",
    "    \"retweet_count\", \"favorite_count\", \"reply_count\", \"quote_count\", \"views\"\n",
    "]\n",
    "\n",
    "assembler = VectorAssembler(inputCols=numeric_cols, outputCol=\"features\")\n",
    "assembled_df = assembler.transform(tweets_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# KMeans at the same time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "k_values = [2, 5, 10, 15, 20]\n",
    "kmeans = [KMeans().setK(k).setSeed(19) for k in k_values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "models = [k.fit(assembled_df) for k in kmeans]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_models = \"/home/jovyan/notebooks/data/models/kmeans/\"\n",
    "#path_models = \"/home/jovyan/notebooks/final_project/equipo/models/kmeans/\"\n",
    "\n",
    "for m, k in zip(models, k_values):\n",
    "    m.save(f\"{path_models}modelk{k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# See results of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 ready\n",
      "Model 5 ready\n",
      "Model 10 ready\n",
      "Model 15 ready\n",
      "Model 20 ready\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeansModel\n",
    "\n",
    "path_models = \"/home/jovyan/notebooks/data/models/kmeans/\"\n",
    "#path_models = \"/home/jovyan/notebooks/final_project/equipo/models/kmeans/\"\n",
    "\n",
    "models = []\n",
    "for i in k_values:\n",
    "    m = KMeansModel.load(f\"{path_models}modelk{i}\")\n",
    "    models.append(m)\n",
    "    print(\"Model\", i, \"ready\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [model.transform(assembled_df) for model in models]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " K values = 2\n",
      "Silhouette score: 0.8348885785955833\n",
      "\n",
      " K values = 5\n",
      "Silhouette score: 0.6588631545348812\n",
      "\n",
      " K values = 10\n",
      "Silhouette score: 0.6720180173656797\n",
      "\n",
      " K values = 15\n",
      "Silhouette score: 0.6437146596205457\n",
      "\n",
      " K values = 20\n",
      "Silhouette score: 0.5677783945643664\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "for i in range(len(k_values)):\n",
    "    print(f\"\\n K values = {k_values[i]}\")\n",
    "    evaluator = ClusteringEvaluator()\n",
    "    silhouette = evaluator.evaluate(predictions[i])\n",
    "    print(f\"Silhouette score: {silhouette}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " K values = 2\n",
      "Cluster Centers: \n",
      "[ 235.2962963   536.59259259   46.85185185   22.88888889 4919.55555556]\n",
      "[  229.2    556.35    49.4     21.1  14830.8 ]\n",
      "\n",
      " K values = 5\n",
      "Cluster Centers: \n",
      "[ 284.85714286  517.14285714   44.42857143   23.35714286 2841.71428571]\n",
      "[  248.625   589.5      63.875    22.25  17436.25 ]\n",
      "[ 228.125  694.75    44.      30.25  9512.125]\n",
      "[  247.           449.88888889    36.44444444    16.88888889\n",
      " 13786.33333333]\n",
      "[ 114.     506.5     55.      17.625 6249.5  ]\n",
      "\n",
      " K values = 10\n",
      "Cluster Centers: \n",
      "[ 338.8  429.2   50.4   21.4 2650.6]\n",
      "[  247.           449.88888889    36.44444444    16.88888889\n",
      " 13786.33333333]\n",
      "[ 253.5  574.5   40.5   36.  8192.5]\n",
      "[  227.           221.            67.33333333    27.33333333\n",
      " 18637.66666667]\n",
      "[ 103.14285714  526.           49.42857143   19.42857143 6420.        ]\n",
      "[  261.6   810.6    61.8    19.2 16715.4]\n",
      "[  124.           787.33333333    49.66666667    30.66666667\n",
      " 11016.33333333]\n",
      "[262.         724.33333333  48.          22.66666667 632.66666667]\n",
      "[ 315.33333333  682.33333333   40.66666667   26.         8887.66666667]\n",
      "[ 242.57142857  470.14285714   45.71428571   22.42857143 4241.28571429]\n",
      "\n",
      " K values = 15\n",
      "Cluster Centers: \n",
      "[  360.    663.     48.5    34.5 12589. ]\n",
      "[321.25 728.5   48.25  18.25 954.75]\n",
      "[ 123.2  649.    37.8   22.6 6644. ]\n",
      "[2.520e+02 1.930e+02 5.500e+01 6.000e+00 1.881e+04]\n",
      "[  183.    801.     47.5    25.  11450. ]\n",
      "[1.07333333e+02 4.83333333e+02 2.10000000e+01 5.66666667e+00\n",
      " 1.45333333e+04]\n",
      "[2.8525e+02 8.3525e+02 7.3250e+01 1.4500e+01 1.6480e+04]\n",
      "[6.0000e+00 7.6000e+02 5.4000e+01 4.2000e+01 1.0149e+04]\n",
      "[ 290.6  639.2   40.6   30.  8609.6]\n",
      "[ 291.33333333  457.5          48.33333333   31.         3068.33333333]\n",
      "[   95.5   533.5    41.5    33.5 17714. ]\n",
      "[ 238.75  395.25   34.75   17.   4388.75]\n",
      "[  295.25   318.25    42.      16.5  13824.75]\n",
      "[  405.   115.    80.    47. 19332.]\n",
      "[  98.66666667  269.           83.66666667    9.33333333 5592.        ]\n",
      "\n",
      " K values = 20\n",
      "Cluster Centers: \n",
      "[ 327.5   215.75   54.25   29.5  3025.25]\n",
      "[3.55666667e+02 8.29333333e+02 7.30000000e+01 1.53333333e+01\n",
      " 1.66330000e+04]\n",
      "[  360.    663.     48.5    34.5 12589. ]\n",
      "[ 315.33333333  682.33333333   40.66666667   26.         8887.66666667]\n",
      "[1.07333333e+02 4.83333333e+02 2.10000000e+01 5.66666667e+00\n",
      " 1.45333333e+04]\n",
      "[262.         724.33333333  48.          22.66666667 632.66666667]\n",
      "[  183.    801.     47.5    25.  11450. ]\n",
      "[  84.  377.   80.    7. 5743.]\n",
      "[ 219.   941.    36.5   34.  3154.5]\n",
      "[ 101.  988.   45.   26. 7156.]\n",
      "[ 229.   390.2   46.6   14.6 4522.2]\n",
      "[  328.5   154.     67.5    26.5 19071. ]\n",
      "[ 499.  741.   49.    5. 1921.]\n",
      "[ 128.75  564.25   36.     21.75 6516.  ]\n",
      "[6.0000e+00 7.6000e+02 5.4000e+01 4.2000e+01 1.0149e+04]\n",
      "[ 253.5  574.5   40.5   36.  8192.5]\n",
      "[  295.25   318.25    42.      16.5  13824.75]\n",
      "[   95.5   533.5    41.5    33.5 17714. ]\n",
      "[7.4000e+01 8.5300e+02 7.4000e+01 1.2000e+01 1.6021e+04]\n",
      "[  22.   60.   77.   16. 5977.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(k_values)):\n",
    "    print(f\"\\n K values = {k_values[i]}\")\n",
    "    print(\"Cluster Centers: \")\n",
    "    for center in models[i].clusterCenters():\n",
    "        print(center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
