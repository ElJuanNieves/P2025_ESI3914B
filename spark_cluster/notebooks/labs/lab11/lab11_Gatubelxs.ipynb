{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../labs/img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> **Procesamiento de Datos Masivos** </center>\n",
    "---\n",
    "### <center> **Primavera 2025** </center>\n",
    "---\n",
    "### <center> **Ejemplos de Aprendizaje Automático (Machine Learning): Decision Trees** </center>\n",
    "\n",
    "---\n",
    "**Equipo**:\n",
    "- Luis Raúl Acosta Mendoza\n",
    "- Samantha Abigail Quintero Valadez \n",
    "- Arturo Benjamin Vergara Romo\n",
    "\n",
    "**Profesor**: Dr. Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creacion de la conexión con el cluster de spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/01 03:18:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MLSpark-Decision-Trees\") \\\n",
    "    .master(\"spark://be6296989c4d:7077\") \\\n",
    "    .config(\"spark.ui.port\",\"4040\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gatubelxs.spark_utils\n",
    "columns_info = [ (\"Id\", \"integer\"),\n",
    "                (\"SepalLenghtCm\", \"double\"),\n",
    "                (\"SepalWidthCm\", \"double\"),\n",
    "                (\"PetalLengthCm\", \"double\"),\n",
    "                (\"PetalWidthCm\", \"double\"),\n",
    "                (\"Species\", \"string\")]\n",
    "\n",
    "schema = gatubelxs.spark_utils.SparkUtils.generate_schema(columns_info)\n",
    "\n",
    "# Create DataFrame\n",
    "strokes_df = spark \\\n",
    "                .read \\\n",
    "                .schema(schema) \\\n",
    "                .option(\"header\", \"true\") \\\n",
    "                .csv(\"/home/jovyan/notebooks/data/Iris.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble the features into a single vector column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "label_indexer = StringIndexer(inputCol=\"Species\", outputCol=\"label\")\n",
    "df_label = label_indexer.fit(strokes_df).transform(strokes_df)\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"SepalLenghtCm\", \"SepalWidthCm\",\"PetalLengthCm\",\"PetalWidthCm\"], outputCol=\"features\")\n",
    "data_with_features = assembler.transform(df_label).select(\"label\", \"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and test sets 80% training data and 20% testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = data_with_features.randomSplit([0.8, 0.2], seed=97)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset\n",
      "+-----+-----------------+\n",
      "|label|         features|\n",
      "+-----+-----------------+\n",
      "|  0.0|[5.1,3.5,1.4,0.2]|\n",
      "|  0.0|[4.9,3.0,1.4,0.2]|\n",
      "|  0.0|[4.7,3.2,1.3,0.2]|\n",
      "|  0.0|[4.6,3.1,1.5,0.2]|\n",
      "|  0.0|[5.0,3.6,1.4,0.2]|\n",
      "|  0.0|[5.4,3.9,1.7,0.4]|\n",
      "|  0.0|[4.6,3.4,1.4,0.3]|\n",
      "|  0.0|[5.0,3.4,1.5,0.2]|\n",
      "|  0.0|[4.4,2.9,1.4,0.2]|\n",
      "|  0.0|[4.9,3.1,1.5,0.1]|\n",
      "|  0.0|[5.4,3.7,1.5,0.2]|\n",
      "|  0.0|[4.8,3.4,1.6,0.2]|\n",
      "|  0.0|[4.8,3.0,1.4,0.1]|\n",
      "|  0.0|[4.3,3.0,1.1,0.1]|\n",
      "|  0.0|[5.8,4.0,1.2,0.2]|\n",
      "|  0.0|[5.7,4.4,1.5,0.4]|\n",
      "|  0.0|[5.4,3.9,1.3,0.4]|\n",
      "|  0.0|[5.1,3.5,1.4,0.3]|\n",
      "|  0.0|[5.7,3.8,1.7,0.3]|\n",
      "|  0.0|[5.1,3.8,1.5,0.3]|\n",
      "+-----+-----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "train set\n",
      "+-----+-----------------+\n",
      "|label|         features|\n",
      "+-----+-----------------+\n",
      "|  0.0|[4.3,3.0,1.1,0.1]|\n",
      "|  0.0|[4.4,2.9,1.4,0.2]|\n",
      "|  0.0|[4.4,3.0,1.3,0.2]|\n",
      "|  0.0|[4.4,3.2,1.3,0.2]|\n",
      "|  0.0|[4.6,3.1,1.5,0.2]|\n",
      "|  0.0|[4.6,3.2,1.4,0.2]|\n",
      "|  0.0|[4.6,3.4,1.4,0.3]|\n",
      "|  0.0|[4.6,3.6,1.0,0.2]|\n",
      "|  0.0|[4.7,3.2,1.6,0.2]|\n",
      "|  0.0|[4.8,3.0,1.4,0.1]|\n",
      "|  0.0|[4.8,3.0,1.4,0.3]|\n",
      "|  0.0|[4.8,3.1,1.6,0.2]|\n",
      "|  0.0|[4.8,3.4,1.6,0.2]|\n",
      "|  0.0|[4.8,3.4,1.9,0.2]|\n",
      "|  0.0|[4.9,3.0,1.4,0.2]|\n",
      "|  0.0|[4.9,3.1,1.5,0.1]|\n",
      "|  0.0|[4.9,3.1,1.5,0.1]|\n",
      "|  0.0|[5.0,3.0,1.6,0.2]|\n",
      "|  0.0|[5.0,3.2,1.2,0.2]|\n",
      "|  0.0|[5.0,3.4,1.5,0.2]|\n",
      "+-----+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Dataset\")\n",
    "data_with_features.show()\n",
    "\n",
    "# Print train dataset\n",
    "print(\"train set\")\n",
    "train_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Initialize and train the Decision Tree model\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree model summary:DecisionTreeClassificationModel: uid=DecisionTreeClassifier_f067db00aaad, depth=5, numNodes=15, numClasses=3, numFeatures=4\n",
      "  If (feature 2 <= 2.5999999999999996)\n",
      "   Predict: 0.0\n",
      "  Else (feature 2 > 2.5999999999999996)\n",
      "   If (feature 2 <= 4.85)\n",
      "    If (feature 3 <= 1.65)\n",
      "     Predict: 1.0\n",
      "    Else (feature 3 > 1.65)\n",
      "     If (feature 1 <= 2.8499999999999996)\n",
      "      Predict: 2.0\n",
      "     Else (feature 1 > 2.8499999999999996)\n",
      "      Predict: 1.0\n",
      "   Else (feature 2 > 4.85)\n",
      "    If (feature 3 <= 1.75)\n",
      "     If (feature 0 <= 6.35)\n",
      "      Predict: 2.0\n",
      "     Else (feature 0 > 6.35)\n",
      "      If (feature 0 <= 6.95)\n",
      "       Predict: 1.0\n",
      "      Else (feature 0 > 6.95)\n",
      "       Predict: 2.0\n",
      "    Else (feature 3 > 1.75)\n",
      "     Predict: 2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_model = dt.fit(train_df)\n",
    "\n",
    "# Display model summary\n",
    "print(\"Decision Tree model summary:{0}\".format(dt_model.toDebugString))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+\n",
      "|         features|prediction|\n",
      "+-----------------+----------+\n",
      "|[4.5,2.3,1.3,0.3]|       0.0|\n",
      "|[4.7,3.2,1.3,0.2]|       0.0|\n",
      "|[4.9,3.1,1.5,0.1]|       0.0|\n",
      "|[5.0,3.3,1.4,0.2]|       0.0|\n",
      "|[5.1,3.3,1.7,0.5]|       0.0|\n",
      "|[5.1,3.8,1.5,0.3]|       0.0|\n",
      "|[5.2,3.4,1.4,0.2]|       0.0|\n",
      "|[5.2,4.1,1.5,0.1]|       0.0|\n",
      "|[5.3,3.7,1.5,0.2]|       0.0|\n",
      "|[5.4,3.9,1.3,0.4]|       0.0|\n",
      "|[5.5,3.5,1.3,0.2]|       0.0|\n",
      "|[5.7,3.8,1.7,0.3]|       0.0|\n",
      "|[5.7,4.4,1.5,0.4]|       0.0|\n",
      "|[5.0,2.3,3.3,1.0]|       1.0|\n",
      "|[5.1,2.5,3.0,1.1]|       1.0|\n",
      "|[5.5,2.4,3.7,1.0]|       1.0|\n",
      "|[5.6,2.9,3.6,1.3]|       1.0|\n",
      "|[5.6,3.0,4.1,1.3]|       1.0|\n",
      "|[5.7,2.6,3.5,1.0]|       1.0|\n",
      "|[5.8,2.7,4.1,1.0]|       1.0|\n",
      "+-----------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the trained model to make predictions on the test data\n",
    "predictions = dt_model.transform(test_df)\n",
    "\n",
    "# Show predictions\n",
    "predictions.select(\"features\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (2.2.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, prediction: double]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Show predictions\n",
    "predictions_ovr.select(\"features\", \"prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9117647058823529\n",
      "Precision: 0.9158496732026143\n",
      "Recall: 0.9117647058823528\n",
      "F1 Score: 0.9125951557093426\n"
     ]
    }
   ],
   "source": [
    "#Tree\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\",\n",
    "                            predictionCol=\"prediction\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions, \n",
    "                  {evaluator.metricName: \"accuracy\"})\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "precision = evaluator.evaluate(predictions,\n",
    "                  {evaluator.metricName: \"weightedPrecision\"})\n",
    "print(f\"Precision: {precision}\")\n",
    "recall = evaluator.evaluate(predictions,\n",
    "                  {evaluator.metricName: \"weightedRecall\"})\n",
    "print(f\"Recall: {recall}\")\n",
    "f1 = evaluator.evaluate(predictions,\n",
    "                {evaluator.metricName: \"f1\"})\n",
    "print(f\"F1 Score: {f1}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/01 03:19:05 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/05/01 03:19:05 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "[Stage 122:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9414532871972319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.classification import OneVsRest\n",
    "\n",
    "# Initialize the LinearSVC classifier for binary\n",
    "# classification\n",
    "lsvc = LinearSVC(maxIter=10, regParam=0.01)\n",
    "# Set up OneVsRest classifier for multi-class\n",
    "# classification\n",
    "ovr = OneVsRest(classifier=lsvc)\n",
    "# Train the model\n",
    "ovr_model = ovr.fit(train_df)\n",
    "\n",
    "predictions_ovr = ovr_model.transform(test_df)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\",\n",
    "                            predictionCol=\"prediction\")\n",
    "f1 = evaluator.evaluate(predictions_ovr,\n",
    "                {evaluator.metricName: \"f1\"})\n",
    "print(f\"F1 Score: {f1}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
