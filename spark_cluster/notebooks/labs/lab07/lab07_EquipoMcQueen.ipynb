{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> **Carrera: Ing. en Sistemas Computacionales** </center>\n",
    "---\n",
    "### <center> **Primavera 2025** </center>\n",
    "---\n",
    "\n",
    "**Lab 07**: Real-time log analyzer\n",
    "\n",
    "**Fecha**: 3 de abril del 2025\n",
    "\n",
    "**Nombre del Estudiante**: Marco Albanese, Vicente Siloe\n",
    "\n",
    "**Profesor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Real-time log analyzer\") \\\n",
    "    .master(\"spark://f8e470126b03:7077\") \\\n",
    "    .config(\"spark.ui.port\",\"4040\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Create SparkContext\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from equipo_mcqueen.traffic_query_listener import TrafficListener\n",
    "\n",
    "spark.streams.addListener(TrafficListener())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "- In teams, build a streaming pipeline that monitors a directory for a **simulated** server log files, analyzes error patterns in real time, and triggers alerts for critical issues (eg., repeated 500 errors).\n",
    "- The notebook with your solution should be named with the following pattern: **spark_cluster/notebooks/labs/lab07/lab07_<team_name>.ipynb**\n",
    "- You need to create one script that generates random log entries (using bash or python). Add this script in the lib folder of your team.\n",
    "- Submit to Canvas a PR link including the script you created to generate random log entries and the Jupyter Notebook with your solution. In the Notebook should be visible at least **three micro batches of the streaming**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_lines = spark \\\n",
    "                .readStream \\\n",
    "                .format(\"text\") \\\n",
    "                .option(\"maxFilesPerTrigger\", 1) \\\n",
    "                .load(\"/home/jovyan/notebooks/data/log_data/input/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- log_array: array (nullable = true)\n",
      " |    |-- element: string (containsNull = false)\n",
      " |-- date: date (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- message: string (nullable = true)\n",
      " |-- server_node: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split\n",
    "\n",
    "logs_df = log_lines.select(split(log_lines.value, \" \").alias(\"log_array\"))\n",
    "logs_df = logs_df.withColumn(\"date\", logs_df[\"log_array\"].getItem(0).cast(\"date\"))\n",
    "logs_df = logs_df.withColumn(\"time\", logs_df[\"log_array\"].getItem(1).cast(\"string\"))\n",
    "logs_df = logs_df.withColumn(\"level\", logs_df[\"log_array\"].getItem(2).cast(\"string\"))\n",
    "logs_df = logs_df.withColumn(\"message\", logs_df[\"log_array\"].getItem(3).cast(\"string\"))\n",
    "logs_df = logs_df.withColumn(\"server_node\", logs_df[\"log_array\"].getItem(4).cast(\"string\"))\n",
    "\n",
    "logs_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter by ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_df = logs_df.filter(logs_df.level == \"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query started: a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\n",
      "Query started: a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\n",
      "Query started: a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\n",
      "-------------------------------------------\n",
      "Batch: 0\n",
      "-------------------------------------------\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                               |date      |time    |level|message                  |server_node  |\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:07:32, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:32|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:32, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:32|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:32, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:32|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:32, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:32|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:32, ERROR, 500-Internal, Server-Error, server-node-2]|2025-04-02|20:07:32|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:32, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:32|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:32, ERROR, 500-Internal, Server-Error, server-node-2]|2025-04-02|20:07:32|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:32, ERROR, 404-Not-Found, server-node-2]             |2025-04-02|20:07:32|ERROR|404-Not-Found            |server-node-2|\n",
      "|[2025-04-02, 20:07:32, ERROR, 404-Not-Found, server-node-1]             |2025-04-02|20:07:32|ERROR|404-Not-Found            |server-node-1|\n",
      "|[2025-04-02, 20:07:32, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:32|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:32, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:32|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:32, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:32|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:32, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:32|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:32, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:32|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:32, ERROR, 500-Internal, Server-Error, server-node-2]|2025-04-02|20:07:32|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:32, ERROR, 500-Internal, Server-Error, server-node-2]|2025-04-02|20:07:32|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:32, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:32|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:32, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:32|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:39.984Z\",\n",
      "  \"batchId\" : 0,\n",
      "  \"numInputRows\" : 75,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 436.046511627907,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 58,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 18,\n",
      "    \"latestOffset\" : 54,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 172,\n",
      "    \"walCommit\" : 18\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : null,\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 0\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 75,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 436.046511627907\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 18\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "-------------------------------------------\n",
      "Batch: 1\n",
      "-------------------------------------------\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                               |date      |time    |level|message                  |server_node  |\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:07:35, ERROR, 404-Not-Found, server-node-3]             |2025-04-02|20:07:35|ERROR|404-Not-Found            |server-node-3|\n",
      "|[2025-04-02, 20:07:35, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:35|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:35, ERROR, Connection-timeout, server-node-1]        |2025-04-02|20:07:35|ERROR|Connection-timeout       |server-node-1|\n",
      "|[2025-04-02, 20:07:35, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:35|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:35, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:35|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:35, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:35|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:35, ERROR, 500-Internal, Server-Error, server-node-1]|2025-04-02|20:07:35|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:35, ERROR, 500-Internal, Server-Error, server-node-1]|2025-04-02|20:07:35|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:35, ERROR, 500-Internal, Server-Error, server-node-1]|2025-04-02|20:07:35|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:35, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:35|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:35, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:35|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:35, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:35|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:35, ERROR, Connection-timeout, server-node-2]        |2025-04-02|20:07:35|ERROR|Connection-timeout       |server-node-2|\n",
      "|[2025-04-02, 20:07:35, ERROR, 500-Internal, Server-Error, server-node-3]|2025-04-02|20:07:35|ERROR|500-Internal             |Server-Error |\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:39.984Z\",\n",
      "  \"batchId\" : 0,\n",
      "  \"numInputRows\" : 75,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 436.046511627907,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 58,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 18,\n",
      "    \"latestOffset\" : 54,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 172,\n",
      "    \"walCommit\" : 18\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : null,\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 0\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 75,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 436.046511627907\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 18\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:39.984Z\",\n",
      "  \"batchId\" : 0,\n",
      "  \"numInputRows\" : 75,\n",
      "  \"inputRowsPerSecond\" : 0.0,\n",
      "  \"processedRowsPerSecond\" : 436.046511627907,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 58,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 18,\n",
      "    \"latestOffset\" : 54,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 172,\n",
      "    \"walCommit\" : 18\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : null,\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 0\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 75,\n",
      "    \"inputRowsPerSecond\" : 0.0,\n",
      "    \"processedRowsPerSecond\" : 436.046511627907\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 18\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:40.156Z\",\n",
      "  \"batchId\" : 1,\n",
      "  \"numInputRows\" : 57,\n",
      "  \"inputRowsPerSecond\" : 331.3953488372093,\n",
      "  \"processedRowsPerSecond\" : 390.41095890410963,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 58,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 24,\n",
      "    \"latestOffset\" : 20,\n",
      "    \"queryPlanning\" : 5,\n",
      "    \"triggerExecution\" : 146,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 0\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 1\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 57,\n",
      "    \"inputRowsPerSecond\" : 331.3953488372093,\n",
      "    \"processedRowsPerSecond\" : 390.41095890410963\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 14\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:40.156Z\",\n",
      "  \"batchId\" : 1,\n",
      "  \"numInputRows\" : 57,\n",
      "  \"inputRowsPerSecond\" : 331.3953488372093,\n",
      "  \"processedRowsPerSecond\" : 390.41095890410963,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 58,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 24,\n",
      "    \"latestOffset\" : 20,\n",
      "    \"queryPlanning\" : 5,\n",
      "    \"triggerExecution\" : 146,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 0\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 1\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 57,\n",
      "    \"inputRowsPerSecond\" : 331.3953488372093,\n",
      "    \"processedRowsPerSecond\" : 390.41095890410963\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 14\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:40.156Z\",\n",
      "  \"batchId\" : 1,\n",
      "  \"numInputRows\" : 57,\n",
      "  \"inputRowsPerSecond\" : 331.3953488372093,\n",
      "  \"processedRowsPerSecond\" : 390.41095890410963,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 58,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 24,\n",
      "    \"latestOffset\" : 20,\n",
      "    \"queryPlanning\" : 5,\n",
      "    \"triggerExecution\" : 146,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 0\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 1\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 57,\n",
      "    \"inputRowsPerSecond\" : 331.3953488372093,\n",
      "    \"processedRowsPerSecond\" : 390.41095890410963\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 14\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "-------------------------------------------\n",
      "Batch: 2\n",
      "-------------------------------------------\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                               |date      |time    |level|message                  |server_node  |\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:07:36, ERROR, 500-Internal, Server-Error, server-node-2]|2025-04-02|20:07:36|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:36, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:36|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:36, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:36|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:36, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:36|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:36, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:36|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:36, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:36|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:36, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:36|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:36, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:36|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:36, ERROR, 500-Internal, Server-Error, server-node-2]|2025-04-02|20:07:36|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:36, ERROR, 500-Internal, Server-Error, server-node-3]|2025-04-02|20:07:36|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:36, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:36|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:36, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:36|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:36, ERROR, 500-Internal, Server-Error, server-node-3]|2025-04-02|20:07:36|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:36, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:36|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:36, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:36|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:42.000Z\",\n",
      "  \"batchId\" : 2,\n",
      "  \"numInputRows\" : 75,\n",
      "  \"inputRowsPerSecond\" : 40.67245119305856,\n",
      "  \"processedRowsPerSecond\" : 568.1818181818181,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 52,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 20,\n",
      "    \"latestOffset\" : 19,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 132,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 1\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 2\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 75,\n",
      "    \"inputRowsPerSecond\" : 40.67245119305856,\n",
      "    \"processedRowsPerSecond\" : 568.1818181818181\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 15\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:42.000Z\",\n",
      "  \"batchId\" : 2,\n",
      "  \"numInputRows\" : 75,\n",
      "  \"inputRowsPerSecond\" : 40.67245119305856,\n",
      "  \"processedRowsPerSecond\" : 568.1818181818181,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 52,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 20,\n",
      "    \"latestOffset\" : 19,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 132,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 1\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 2\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 75,\n",
      "    \"inputRowsPerSecond\" : 40.67245119305856,\n",
      "    \"processedRowsPerSecond\" : 568.1818181818181\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 15\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:42.000Z\",\n",
      "  \"batchId\" : 2,\n",
      "  \"numInputRows\" : 75,\n",
      "  \"inputRowsPerSecond\" : 40.67245119305856,\n",
      "  \"processedRowsPerSecond\" : 568.1818181818181,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 52,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 20,\n",
      "    \"latestOffset\" : 19,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 132,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 1\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 2\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 75,\n",
      "    \"inputRowsPerSecond\" : 40.67245119305856,\n",
      "    \"processedRowsPerSecond\" : 568.1818181818181\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 15\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "-------------------------------------------\n",
      "Batch: 3\n",
      "-------------------------------------------\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                               |date      |time    |level|message                  |server_node  |\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:07:38, ERROR, 500-Internal, Server-Error, server-node-1]|2025-04-02|20:07:38|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:38, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:38|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:38, ERROR, 500-Internal, Server-Error, server-node-3]|2025-04-02|20:07:38|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:38, ERROR, Connection-timeout, server-node-3]        |2025-04-02|20:07:38|ERROR|Connection-timeout       |server-node-3|\n",
      "|[2025-04-02, 20:07:38, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:38|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:38, ERROR, 500-Internal, Server-Error, server-node-1]|2025-04-02|20:07:38|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:38, ERROR, 500-Internal, Server-Error, server-node-1]|2025-04-02|20:07:38|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:38, ERROR, Connection-timeout, server-node-1]        |2025-04-02|20:07:38|ERROR|Connection-timeout       |server-node-1|\n",
      "|[2025-04-02, 20:07:38, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:38|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:38, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:38|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:38, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:38|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:38, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:38|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:38, ERROR, 500-Internal, Server-Error, server-node-3]|2025-04-02|20:07:38|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:38, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:38|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:38, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:38|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:38, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:38|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:44.000Z\",\n",
      "  \"batchId\" : 3,\n",
      "  \"numInputRows\" : 78,\n",
      "  \"inputRowsPerSecond\" : 39.0,\n",
      "  \"processedRowsPerSecond\" : 565.2173913043478,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 55,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 21,\n",
      "    \"latestOffset\" : 20,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 137,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 2\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 3\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 78,\n",
      "    \"inputRowsPerSecond\" : 39.0,\n",
      "    \"processedRowsPerSecond\" : 565.2173913043478\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 16\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:44.000Z\",\n",
      "  \"batchId\" : 3,\n",
      "  \"numInputRows\" : 78,\n",
      "  \"inputRowsPerSecond\" : 39.0,\n",
      "  \"processedRowsPerSecond\" : 565.2173913043478,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 55,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 21,\n",
      "    \"latestOffset\" : 20,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 137,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 2\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 3\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 78,\n",
      "    \"inputRowsPerSecond\" : 39.0,\n",
      "    \"processedRowsPerSecond\" : 565.2173913043478\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 16\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:44.000Z\",\n",
      "  \"batchId\" : 3,\n",
      "  \"numInputRows\" : 78,\n",
      "  \"inputRowsPerSecond\" : 39.0,\n",
      "  \"processedRowsPerSecond\" : 565.2173913043478,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 55,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 21,\n",
      "    \"latestOffset\" : 20,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 137,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 2\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 3\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 78,\n",
      "    \"inputRowsPerSecond\" : 39.0,\n",
      "    \"processedRowsPerSecond\" : 565.2173913043478\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 16\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "-------------------------------------------\n",
      "Batch: 4\n",
      "-------------------------------------------\n",
      "+-----------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                              |date      |time    |level|message                  |server_node  |\n",
      "+-----------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:07:40, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:40|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:40, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:40|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:40, ERROR, Connection-timeout, server-node-2]       |2025-04-02|20:07:40|ERROR|Connection-timeout       |server-node-2|\n",
      "|[2025-04-02, 20:07:40, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:40|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:40, ERROR, Connection-timeout, server-node-3]       |2025-04-02|20:07:40|ERROR|Connection-timeout       |server-node-3|\n",
      "|[2025-04-02, 20:07:40, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:40|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:40, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:40|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:40, ERROR, Connection-timeout, server-node-1]       |2025-04-02|20:07:40|ERROR|Connection-timeout       |server-node-1|\n",
      "|[2025-04-02, 20:07:40, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:40|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:40, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:40|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:40, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:40|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:40, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:40|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:40, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:40|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:40, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:40|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:40, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:40|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "+-----------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:46.000Z\",\n",
      "  \"batchId\" : 4,\n",
      "  \"numInputRows\" : 73,\n",
      "  \"inputRowsPerSecond\" : 36.5,\n",
      "  \"processedRowsPerSecond\" : 403.31491712707185,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 48,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 21,\n",
      "    \"latestOffset\" : 68,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 181,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 3\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 4\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 73,\n",
      "    \"inputRowsPerSecond\" : 36.5,\n",
      "    \"processedRowsPerSecond\" : 403.31491712707185\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 15\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:46.000Z\",\n",
      "  \"batchId\" : 4,\n",
      "  \"numInputRows\" : 73,\n",
      "  \"inputRowsPerSecond\" : 36.5,\n",
      "  \"processedRowsPerSecond\" : 403.31491712707185,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 48,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 21,\n",
      "    \"latestOffset\" : 68,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 181,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 3\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 4\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 73,\n",
      "    \"inputRowsPerSecond\" : 36.5,\n",
      "    \"processedRowsPerSecond\" : 403.31491712707185\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 15\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:46.000Z\",\n",
      "  \"batchId\" : 4,\n",
      "  \"numInputRows\" : 73,\n",
      "  \"inputRowsPerSecond\" : 36.5,\n",
      "  \"processedRowsPerSecond\" : 403.31491712707185,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 48,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 21,\n",
      "    \"latestOffset\" : 68,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 181,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 3\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 4\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 73,\n",
      "    \"inputRowsPerSecond\" : 36.5,\n",
      "    \"processedRowsPerSecond\" : 403.31491712707185\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 15\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "-------------------------------------------\n",
      "Batch: 5\n",
      "-------------------------------------------\n",
      "+-----------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                              |date      |time    |level|message                  |server_node  |\n",
      "+-----------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:07:42, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:42|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:42, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:42|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:42, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:42|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:42, ERROR, Connection-timeout, server-node-3]       |2025-04-02|20:07:42|ERROR|Connection-timeout       |server-node-3|\n",
      "|[2025-04-02, 20:07:42, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:42|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:42, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:42|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:42, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:42|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:42, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:42|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "+-----------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:48.000Z\",\n",
      "  \"batchId\" : 5,\n",
      "  \"numInputRows\" : 51,\n",
      "  \"inputRowsPerSecond\" : 25.5,\n",
      "  \"processedRowsPerSecond\" : 364.2857142857143,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 56,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 19,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 140,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 4\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 5\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 51,\n",
      "    \"inputRowsPerSecond\" : 25.5,\n",
      "    \"processedRowsPerSecond\" : 364.2857142857143\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 8\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:48.000Z\",\n",
      "  \"batchId\" : 5,\n",
      "  \"numInputRows\" : 51,\n",
      "  \"inputRowsPerSecond\" : 25.5,\n",
      "  \"processedRowsPerSecond\" : 364.2857142857143,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 56,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 19,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 140,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 4\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 5\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 51,\n",
      "    \"inputRowsPerSecond\" : 25.5,\n",
      "    \"processedRowsPerSecond\" : 364.2857142857143\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 8\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:48.000Z\",\n",
      "  \"batchId\" : 5,\n",
      "  \"numInputRows\" : 51,\n",
      "  \"inputRowsPerSecond\" : 25.5,\n",
      "  \"processedRowsPerSecond\" : 364.2857142857143,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 56,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 19,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 140,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 4\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 5\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 51,\n",
      "    \"inputRowsPerSecond\" : 25.5,\n",
      "    \"processedRowsPerSecond\" : 364.2857142857143\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 8\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "-------------------------------------------\n",
      "Batch: 6\n",
      "-------------------------------------------\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                               |date      |time    |level|message                  |server_node  |\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:07:44, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:44|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:44, ERROR, 500-Internal, Server-Error, server-node-2]|2025-04-02|20:07:44|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:44, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:44|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:44, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:44|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:44, ERROR, 500-Internal, Server-Error, server-node-1]|2025-04-02|20:07:44|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:44, ERROR, Connection-timeout, server-node-1]        |2025-04-02|20:07:44|ERROR|Connection-timeout       |server-node-1|\n",
      "|[2025-04-02, 20:07:44, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:44|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:44, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:44|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:44, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:44|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:44, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:44|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:44, ERROR, Connection-timeout, server-node-3]        |2025-04-02|20:07:44|ERROR|Connection-timeout       |server-node-3|\n",
      "|[2025-04-02, 20:07:44, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:44|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:44, ERROR, Connection-timeout, server-node-3]        |2025-04-02|20:07:44|ERROR|Connection-timeout       |server-node-3|\n",
      "|[2025-04-02, 20:07:44, ERROR, 404-Not-Found, server-node-2]             |2025-04-02|20:07:44|ERROR|404-Not-Found            |server-node-2|\n",
      "|[2025-04-02, 20:07:44, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:44|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:44, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:44|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:44, ERROR, Connection-timeout, server-node-1]        |2025-04-02|20:07:44|ERROR|Connection-timeout       |server-node-1|\n",
      "|[2025-04-02, 20:07:44, ERROR, Connection-timeout, server-node-3]        |2025-04-02|20:07:44|ERROR|Connection-timeout       |server-node-3|\n",
      "|[2025-04-02, 20:07:44, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:44|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:44, ERROR, 404-Not-Found, server-node-1]             |2025-04-02|20:07:44|ERROR|404-Not-Found            |server-node-1|\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:50.000Z\",\n",
      "  \"batchId\" : 6,\n",
      "  \"numInputRows\" : 80,\n",
      "  \"inputRowsPerSecond\" : 40.0,\n",
      "  \"processedRowsPerSecond\" : 592.5925925925926,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 50,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 23,\n",
      "    \"latestOffset\" : 19,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 135,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 5\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 6\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 80,\n",
      "    \"inputRowsPerSecond\" : 40.0,\n",
      "    \"processedRowsPerSecond\" : 592.5925925925926\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 27\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:50.000Z\",\n",
      "  \"batchId\" : 6,\n",
      "  \"numInputRows\" : 80,\n",
      "  \"inputRowsPerSecond\" : 40.0,\n",
      "  \"processedRowsPerSecond\" : 592.5925925925926,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 50,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 23,\n",
      "    \"latestOffset\" : 19,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 135,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 5\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 6\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 80,\n",
      "    \"inputRowsPerSecond\" : 40.0,\n",
      "    \"processedRowsPerSecond\" : 592.5925925925926\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 27\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:50.000Z\",\n",
      "  \"batchId\" : 6,\n",
      "  \"numInputRows\" : 80,\n",
      "  \"inputRowsPerSecond\" : 40.0,\n",
      "  \"processedRowsPerSecond\" : 592.5925925925926,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 50,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 23,\n",
      "    \"latestOffset\" : 19,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 135,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 5\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 6\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 80,\n",
      "    \"inputRowsPerSecond\" : 40.0,\n",
      "    \"processedRowsPerSecond\" : 592.5925925925926\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 27\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "-------------------------------------------\n",
      "Batch: 7\n",
      "-------------------------------------------\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                               |date      |time    |level|message                  |server_node  |\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:07:47, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:47|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:47, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:47|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:47, ERROR, Connection-timeout, server-node-2]        |2025-04-02|20:07:47|ERROR|Connection-timeout       |server-node-2|\n",
      "|[2025-04-02, 20:07:47, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:47|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:47, ERROR, Connection-timeout, server-node-3]        |2025-04-02|20:07:47|ERROR|Connection-timeout       |server-node-3|\n",
      "|[2025-04-02, 20:07:47, ERROR, Connection-timeout, server-node-2]        |2025-04-02|20:07:47|ERROR|Connection-timeout       |server-node-2|\n",
      "|[2025-04-02, 20:07:47, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:47|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:47, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:47|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:47, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:47|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:47, ERROR, 404-Not-Found, server-node-1]             |2025-04-02|20:07:47|ERROR|404-Not-Found            |server-node-1|\n",
      "|[2025-04-02, 20:07:47, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:47|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:47, ERROR, 404-Not-Found, server-node-2]             |2025-04-02|20:07:47|ERROR|404-Not-Found            |server-node-2|\n",
      "|[2025-04-02, 20:07:47, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:47|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:47, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:47|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:47, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:47|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:47, ERROR, 500-Internal, Server-Error, server-node-2]|2025-04-02|20:07:47|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:47, ERROR, 500-Internal, Server-Error, server-node-1]|2025-04-02|20:07:47|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:47, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:47|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:47, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:47|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:52.000Z\",\n",
      "  \"batchId\" : 7,\n",
      "  \"numInputRows\" : 67,\n",
      "  \"inputRowsPerSecond\" : 33.5,\n",
      "  \"processedRowsPerSecond\" : 320.57416267942585,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 52,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 20,\n",
      "    \"latestOffset\" : 94,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 209,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 6\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 7\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 67,\n",
      "    \"inputRowsPerSecond\" : 33.5,\n",
      "    \"processedRowsPerSecond\" : 320.57416267942585\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 19\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:52.000Z\",\n",
      "  \"batchId\" : 7,\n",
      "  \"numInputRows\" : 67,\n",
      "  \"inputRowsPerSecond\" : 33.5,\n",
      "  \"processedRowsPerSecond\" : 320.57416267942585,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 52,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 20,\n",
      "    \"latestOffset\" : 94,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 209,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 6\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 7\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 67,\n",
      "    \"inputRowsPerSecond\" : 33.5,\n",
      "    \"processedRowsPerSecond\" : 320.57416267942585\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 19\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:52.000Z\",\n",
      "  \"batchId\" : 7,\n",
      "  \"numInputRows\" : 67,\n",
      "  \"inputRowsPerSecond\" : 33.5,\n",
      "  \"processedRowsPerSecond\" : 320.57416267942585,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 52,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 20,\n",
      "    \"latestOffset\" : 94,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 209,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 6\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 7\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 67,\n",
      "    \"inputRowsPerSecond\" : 33.5,\n",
      "    \"processedRowsPerSecond\" : 320.57416267942585\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 19\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "-------------------------------------------\n",
      "Batch: 8\n",
      "-------------------------------------------\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                               |date      |time    |level|message                  |server_node  |\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:07:48, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:48|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:48, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:48|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:48, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:48|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:48, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:48|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:48, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:48|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:48, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:48|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:48, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:48|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:48, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:48|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:48, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:48|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:48, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:48|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:48, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:48|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:48, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:48|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:48, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:48|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:48, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:48|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:48, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:48|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:48, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:48|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:48, ERROR, Connection-timeout, server-node-3]        |2025-04-02|20:07:48|ERROR|Connection-timeout       |server-node-3|\n",
      "|[2025-04-02, 20:07:48, ERROR, 500-Internal, Server-Error, server-node-3]|2025-04-02|20:07:48|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:48, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:48|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:48, ERROR, Connection-timeout, server-node-1]        |2025-04-02|20:07:48|ERROR|Connection-timeout       |server-node-1|\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:54.000Z\",\n",
      "  \"batchId\" : 8,\n",
      "  \"numInputRows\" : 79,\n",
      "  \"inputRowsPerSecond\" : 39.5,\n",
      "  \"processedRowsPerSecond\" : 580.8823529411765,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 54,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 18,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 136,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 7\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 8\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 79,\n",
      "    \"inputRowsPerSecond\" : 39.5,\n",
      "    \"processedRowsPerSecond\" : 580.8823529411765\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 20\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:54.000Z\",\n",
      "  \"batchId\" : 8,\n",
      "  \"numInputRows\" : 79,\n",
      "  \"inputRowsPerSecond\" : 39.5,\n",
      "  \"processedRowsPerSecond\" : 580.8823529411765,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 54,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 18,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 136,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 7\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 8\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 79,\n",
      "    \"inputRowsPerSecond\" : 39.5,\n",
      "    \"processedRowsPerSecond\" : 580.8823529411765\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 20\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:54.000Z\",\n",
      "  \"batchId\" : 8,\n",
      "  \"numInputRows\" : 79,\n",
      "  \"inputRowsPerSecond\" : 39.5,\n",
      "  \"processedRowsPerSecond\" : 580.8823529411765,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 54,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 18,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 136,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 7\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 8\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 79,\n",
      "    \"inputRowsPerSecond\" : 39.5,\n",
      "    \"processedRowsPerSecond\" : 580.8823529411765\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 20\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "-------------------------------------------\n",
      "Batch: 9\n",
      "-------------------------------------------\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                               |date      |time    |level|message                  |server_node  |\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:07:50, ERROR, 500-Internal, Server-Error, server-node-3]|2025-04-02|20:07:50|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:50, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:50|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:50, ERROR, 500-Internal, Server-Error, server-node-3]|2025-04-02|20:07:50|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:50, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:50|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:50, ERROR, 500-Internal, Server-Error, server-node-1]|2025-04-02|20:07:50|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:50, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:50|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:50, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:50|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:50, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:50|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:50, ERROR, 500-Internal, Server-Error, server-node-3]|2025-04-02|20:07:50|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:50, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:50|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:50, ERROR, 404-Not-Found, server-node-2]             |2025-04-02|20:07:50|ERROR|404-Not-Found            |server-node-2|\n",
      "|[2025-04-02, 20:07:50, ERROR, 404-Not-Found, server-node-3]             |2025-04-02|20:07:50|ERROR|404-Not-Found            |server-node-3|\n",
      "|[2025-04-02, 20:07:50, ERROR, 500-Internal, Server-Error, server-node-3]|2025-04-02|20:07:50|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:50, ERROR, Connection-timeout, server-node-2]        |2025-04-02|20:07:50|ERROR|Connection-timeout       |server-node-2|\n",
      "|[2025-04-02, 20:07:50, ERROR, 404-Not-Found, server-node-3]             |2025-04-02|20:07:50|ERROR|404-Not-Found            |server-node-3|\n",
      "|[2025-04-02, 20:07:50, ERROR, 500-Internal, Server-Error, server-node-1]|2025-04-02|20:07:50|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:50, ERROR, 404-Not-Found, server-node-3]             |2025-04-02|20:07:50|ERROR|404-Not-Found            |server-node-3|\n",
      "|[2025-04-02, 20:07:50, ERROR, Connection-timeout, server-node-2]        |2025-04-02|20:07:50|ERROR|Connection-timeout       |server-node-2|\n",
      "|[2025-04-02, 20:07:50, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:50|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:50, ERROR, Connection-timeout, server-node-2]        |2025-04-02|20:07:50|ERROR|Connection-timeout       |server-node-2|\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:56.000Z\",\n",
      "  \"batchId\" : 9,\n",
      "  \"numInputRows\" : 78,\n",
      "  \"inputRowsPerSecond\" : 39.0,\n",
      "  \"processedRowsPerSecond\" : 520.0,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 61,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 20,\n",
      "    \"latestOffset\" : 20,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 150,\n",
      "    \"walCommit\" : 26\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 8\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 9\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 78,\n",
      "    \"inputRowsPerSecond\" : 39.0,\n",
      "    \"processedRowsPerSecond\" : 520.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 20\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:56.000Z\",\n",
      "  \"batchId\" : 9,\n",
      "  \"numInputRows\" : 78,\n",
      "  \"inputRowsPerSecond\" : 39.0,\n",
      "  \"processedRowsPerSecond\" : 520.0,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 61,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 20,\n",
      "    \"latestOffset\" : 20,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 150,\n",
      "    \"walCommit\" : 26\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 8\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 9\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 78,\n",
      "    \"inputRowsPerSecond\" : 39.0,\n",
      "    \"processedRowsPerSecond\" : 520.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 20\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:56.000Z\",\n",
      "  \"batchId\" : 9,\n",
      "  \"numInputRows\" : 78,\n",
      "  \"inputRowsPerSecond\" : 39.0,\n",
      "  \"processedRowsPerSecond\" : 520.0,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 61,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 20,\n",
      "    \"latestOffset\" : 20,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 150,\n",
      "    \"walCommit\" : 26\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 8\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 9\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 78,\n",
      "    \"inputRowsPerSecond\" : 39.0,\n",
      "    \"processedRowsPerSecond\" : 520.0\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 20\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "-------------------------------------------\n",
      "Batch: 10\n",
      "-------------------------------------------\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                               |date      |time    |level|message                  |server_node  |\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:07:51, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:51|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:51, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:51|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:51, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:51|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:51, ERROR, 500-Internal, Server-Error, server-node-2]|2025-04-02|20:07:51|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:51, ERROR, Connection-timeout, server-node-3]        |2025-04-02|20:07:51|ERROR|Connection-timeout       |server-node-3|\n",
      "|[2025-04-02, 20:07:51, ERROR, Connection-timeout, server-node-3]        |2025-04-02|20:07:51|ERROR|Connection-timeout       |server-node-3|\n",
      "|[2025-04-02, 20:07:51, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:51|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:51, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:51|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:51, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:51|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:51, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:51|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:51, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:51|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:51, ERROR, Connection-timeout, server-node-3]        |2025-04-02|20:07:51|ERROR|Connection-timeout       |server-node-3|\n",
      "|[2025-04-02, 20:07:51, ERROR, Connection-timeout, server-node-1]        |2025-04-02|20:07:51|ERROR|Connection-timeout       |server-node-1|\n",
      "|[2025-04-02, 20:07:51, ERROR, 404-Not-Found, server-node-3]             |2025-04-02|20:07:51|ERROR|404-Not-Found            |server-node-3|\n",
      "|[2025-04-02, 20:07:51, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:51|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:58.001Z\",\n",
      "  \"batchId\" : 10,\n",
      "  \"numInputRows\" : 49,\n",
      "  \"inputRowsPerSecond\" : 24.487756121939032,\n",
      "  \"processedRowsPerSecond\" : 357.6642335766423,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 54,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 20,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 137,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 9\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 10\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 49,\n",
      "    \"inputRowsPerSecond\" : 24.487756121939032,\n",
      "    \"processedRowsPerSecond\" : 357.6642335766423\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 15\n",
      "  }\n",
      "}\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:58.001Z\",\n",
      "  \"batchId\" : 10,\n",
      "  \"numInputRows\" : 49,\n",
      "  \"inputRowsPerSecond\" : 24.487756121939032,\n",
      "  \"processedRowsPerSecond\" : 357.6642335766423,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 54,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 20,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 137,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 9\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 10\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 49,\n",
      "    \"inputRowsPerSecond\" : 24.487756121939032,\n",
      "    \"processedRowsPerSecond\" : 357.6642335766423\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 15\n",
      "  }\n",
      "}\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:07:58.001Z\",\n",
      "  \"batchId\" : 10,\n",
      "  \"numInputRows\" : 49,\n",
      "  \"inputRowsPerSecond\" : 24.487756121939032,\n",
      "  \"processedRowsPerSecond\" : 357.6642335766423,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 54,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 20,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 137,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 9\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 10\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 49,\n",
      "    \"inputRowsPerSecond\" : 24.487756121939032,\n",
      "    \"processedRowsPerSecond\" : 357.6642335766423\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 15\n",
      "  }\n",
      "}\n",
      "-------------------------------------------\n",
      "Batch: 11\n",
      "-------------------------------------------\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                               |date      |time    |level|message                  |server_node  |\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:07:52, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:52|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:52, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:52|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:52, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:52|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:52, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:52|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:52, ERROR, 404-Not-Found, server-node-2]             |2025-04-02|20:07:52|ERROR|404-Not-Found            |server-node-2|\n",
      "|[2025-04-02, 20:07:52, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:52|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:52, ERROR, 500-Internal, Server-Error, server-node-2]|2025-04-02|20:07:52|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:52, ERROR, 404-Not-Found, server-node-3]             |2025-04-02|20:07:52|ERROR|404-Not-Found            |server-node-3|\n",
      "|[2025-04-02, 20:07:52, ERROR, 500-Internal, Server-Error, server-node-3]|2025-04-02|20:07:52|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:52, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:52|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:52, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:52|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:52, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:52|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:52, ERROR, 404-Not-Found, server-node-3]             |2025-04-02|20:07:52|ERROR|404-Not-Found            |server-node-3|\n",
      "|[2025-04-02, 20:07:52, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:52|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:52, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:52|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:52, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:52|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:00.000Z\",\n",
      "  \"batchId\" : 11,\n",
      "  \"numInputRows\" : 62,\n",
      "  \"inputRowsPerSecond\" : 31.015507753876935,\n",
      "  \"processedRowsPerSecond\" : 245.0592885375494,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 61,\n",
      "    \"commitOffsets\" : 22,\n",
      "    \"getBatch\" : 24,\n",
      "    \"latestOffset\" : 121,\n",
      "    \"queryPlanning\" : 5,\n",
      "    \"triggerExecution\" : 253,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 10\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 11\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 62,\n",
      "    \"inputRowsPerSecond\" : 31.015507753876935,\n",
      "    \"processedRowsPerSecond\" : 245.0592885375494\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 16\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:00.000Z\",\n",
      "  \"batchId\" : 11,\n",
      "  \"numInputRows\" : 62,\n",
      "  \"inputRowsPerSecond\" : 31.015507753876935,\n",
      "  \"processedRowsPerSecond\" : 245.0592885375494,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 61,\n",
      "    \"commitOffsets\" : 22,\n",
      "    \"getBatch\" : 24,\n",
      "    \"latestOffset\" : 121,\n",
      "    \"queryPlanning\" : 5,\n",
      "    \"triggerExecution\" : 253,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 10\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 11\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 62,\n",
      "    \"inputRowsPerSecond\" : 31.015507753876935,\n",
      "    \"processedRowsPerSecond\" : 245.0592885375494\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 16\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:00.000Z\",\n",
      "  \"batchId\" : 11,\n",
      "  \"numInputRows\" : 62,\n",
      "  \"inputRowsPerSecond\" : 31.015507753876935,\n",
      "  \"processedRowsPerSecond\" : 245.0592885375494,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 61,\n",
      "    \"commitOffsets\" : 22,\n",
      "    \"getBatch\" : 24,\n",
      "    \"latestOffset\" : 121,\n",
      "    \"queryPlanning\" : 5,\n",
      "    \"triggerExecution\" : 253,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 10\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 11\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 62,\n",
      "    \"inputRowsPerSecond\" : 31.015507753876935,\n",
      "    \"processedRowsPerSecond\" : 245.0592885375494\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 16\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "-------------------------------------------\n",
      "Batch: 12\n",
      "-------------------------------------------\n",
      "+-----------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                              |date      |time    |level|message                  |server_node  |\n",
      "+-----------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:07:55, ERROR, 404-Not-Found, server-node-3]            |2025-04-02|20:07:55|ERROR|404-Not-Found            |server-node-3|\n",
      "|[2025-04-02, 20:07:55, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:55|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:55, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:55|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:55, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:55|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:55, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:55|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:55, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:55|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:55, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:07:55|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "+-----------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:02.000Z\",\n",
      "  \"batchId\" : 12,\n",
      "  \"numInputRows\" : 54,\n",
      "  \"inputRowsPerSecond\" : 27.0,\n",
      "  \"processedRowsPerSecond\" : 402.98507462686564,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 50,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 20,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 134,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 11\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 12\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 54,\n",
      "    \"inputRowsPerSecond\" : 27.0,\n",
      "    \"processedRowsPerSecond\" : 402.98507462686564\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 7\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:02.000Z\",\n",
      "  \"batchId\" : 12,\n",
      "  \"numInputRows\" : 54,\n",
      "  \"inputRowsPerSecond\" : 27.0,\n",
      "  \"processedRowsPerSecond\" : 402.98507462686564,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 50,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 20,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 134,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 11\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 12\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 54,\n",
      "    \"inputRowsPerSecond\" : 27.0,\n",
      "    \"processedRowsPerSecond\" : 402.98507462686564\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 7\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:02.000Z\",\n",
      "  \"batchId\" : 12,\n",
      "  \"numInputRows\" : 54,\n",
      "  \"inputRowsPerSecond\" : 27.0,\n",
      "  \"processedRowsPerSecond\" : 402.98507462686564,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 50,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 20,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 134,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 11\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 12\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 54,\n",
      "    \"inputRowsPerSecond\" : 27.0,\n",
      "    \"processedRowsPerSecond\" : 402.98507462686564\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 7\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "-------------------------------------------\n",
      "Batch: 13\n",
      "-------------------------------------------\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                               |date      |time    |level|message                  |server_node  |\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:07:57, ERROR, Connection-timeout, server-node-1]        |2025-04-02|20:07:57|ERROR|Connection-timeout       |server-node-1|\n",
      "|[2025-04-02, 20:07:57, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:57|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:57, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:57|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:57, ERROR, Connection-timeout, server-node-3]        |2025-04-02|20:07:57|ERROR|Connection-timeout       |server-node-3|\n",
      "|[2025-04-02, 20:07:57, ERROR, 500-Internal, Server-Error, server-node-2]|2025-04-02|20:07:57|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:57, ERROR, 404-Not-Found, server-node-3]             |2025-04-02|20:07:57|ERROR|404-Not-Found            |server-node-3|\n",
      "|[2025-04-02, 20:07:57, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:57|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:57, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:57|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:57, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:57|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:57, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:57|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:57, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:57|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:57, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:57|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:57, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:57|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:57, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:57|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:07:57, ERROR, 500-Internal, Server-Error, server-node-1]|2025-04-02|20:07:57|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:07:57, ERROR, 404-Not-Found, server-node-2]             |2025-04-02|20:07:57|ERROR|404-Not-Found            |server-node-2|\n",
      "|[2025-04-02, 20:07:57, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:07:57|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:04.000Z\",\n",
      "  \"batchId\" : 13,\n",
      "  \"numInputRows\" : 78,\n",
      "  \"inputRowsPerSecond\" : 39.0,\n",
      "  \"processedRowsPerSecond\" : 582.0895522388059,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 53,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 21,\n",
      "    \"latestOffset\" : 19,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 134,\n",
      "    \"walCommit\" : 18\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 12\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 13\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 78,\n",
      "    \"inputRowsPerSecond\" : 39.0,\n",
      "    \"processedRowsPerSecond\" : 582.0895522388059\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 17\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:04.000Z\",\n",
      "  \"batchId\" : 13,\n",
      "  \"numInputRows\" : 78,\n",
      "  \"inputRowsPerSecond\" : 39.0,\n",
      "  \"processedRowsPerSecond\" : 582.0895522388059,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 53,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 21,\n",
      "    \"latestOffset\" : 19,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 134,\n",
      "    \"walCommit\" : 18\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 12\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 13\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 78,\n",
      "    \"inputRowsPerSecond\" : 39.0,\n",
      "    \"processedRowsPerSecond\" : 582.0895522388059\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 17\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:04.000Z\",\n",
      "  \"batchId\" : 13,\n",
      "  \"numInputRows\" : 78,\n",
      "  \"inputRowsPerSecond\" : 39.0,\n",
      "  \"processedRowsPerSecond\" : 582.0895522388059,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 53,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 21,\n",
      "    \"latestOffset\" : 19,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 134,\n",
      "    \"walCommit\" : 18\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 12\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 13\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 78,\n",
      "    \"inputRowsPerSecond\" : 39.0,\n",
      "    \"processedRowsPerSecond\" : 582.0895522388059\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 17\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "-------------------------------------------\n",
      "Batch: 14\n",
      "-------------------------------------------\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                               |date      |time    |level|message                  |server_node  |\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:08:00, ERROR, 404-Not-Found, server-node-3]             |2025-04-02|20:08:00|ERROR|404-Not-Found            |server-node-3|\n",
      "|[2025-04-02, 20:08:00, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:00|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:00, ERROR, 404-Not-Found, server-node-1]             |2025-04-02|20:08:00|ERROR|404-Not-Found            |server-node-1|\n",
      "|[2025-04-02, 20:08:00, ERROR, 500-Internal, Server-Error, server-node-3]|2025-04-02|20:08:00|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:08:00, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:00|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:00, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:00|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:00, ERROR, 500-Internal, Server-Error, server-node-3]|2025-04-02|20:08:00|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:08:00, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:00|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:00, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:00|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:00, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:00|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:00, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:00|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:00, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:00|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:00, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:00|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:00, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:00|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:00, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:00|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:00, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:00|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:00, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:00|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:06.000Z\",\n",
      "  \"batchId\" : 14,\n",
      "  \"numInputRows\" : 68,\n",
      "  \"inputRowsPerSecond\" : 34.0,\n",
      "  \"processedRowsPerSecond\" : 258.5551330798479,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 55,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 143,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 263,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 13\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 14\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 68,\n",
      "    \"inputRowsPerSecond\" : 34.0,\n",
      "    \"processedRowsPerSecond\" : 258.5551330798479\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 17\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:06.000Z\",\n",
      "  \"batchId\" : 14,\n",
      "  \"numInputRows\" : 68,\n",
      "  \"inputRowsPerSecond\" : 34.0,\n",
      "  \"processedRowsPerSecond\" : 258.5551330798479,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 55,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 143,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 263,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 13\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 14\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 68,\n",
      "    \"inputRowsPerSecond\" : 34.0,\n",
      "    \"processedRowsPerSecond\" : 258.5551330798479\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 17\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:06.000Z\",\n",
      "  \"batchId\" : 14,\n",
      "  \"numInputRows\" : 68,\n",
      "  \"inputRowsPerSecond\" : 34.0,\n",
      "  \"processedRowsPerSecond\" : 258.5551330798479,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 55,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 143,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 263,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 13\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 14\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 68,\n",
      "    \"inputRowsPerSecond\" : 34.0,\n",
      "    \"processedRowsPerSecond\" : 258.5551330798479\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 17\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "-------------------------------------------\n",
      "Batch: 15\n",
      "-------------------------------------------\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                               |date      |time    |level|message                  |server_node  |\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:08:03, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:03|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:03, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:03|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:03, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:03|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:03, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:03|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:03, ERROR, 500-Internal, Server-Error, server-node-3]|2025-04-02|20:08:03|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:08:03, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:03|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:03, ERROR, Connection-timeout, server-node-1]        |2025-04-02|20:08:03|ERROR|Connection-timeout       |server-node-1|\n",
      "|[2025-04-02, 20:08:03, ERROR, 404-Not-Found, server-node-2]             |2025-04-02|20:08:03|ERROR|404-Not-Found            |server-node-2|\n",
      "|[2025-04-02, 20:08:03, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:03|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:03, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:03|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:08.000Z\",\n",
      "  \"batchId\" : 15,\n",
      "  \"numInputRows\" : 62,\n",
      "  \"inputRowsPerSecond\" : 31.0,\n",
      "  \"processedRowsPerSecond\" : 452.5547445255474,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 53,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 23,\n",
      "    \"latestOffset\" : 20,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 137,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 14\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 15\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 62,\n",
      "    \"inputRowsPerSecond\" : 31.0,\n",
      "    \"processedRowsPerSecond\" : 452.5547445255474\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 10\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:08.000Z\",\n",
      "  \"batchId\" : 15,\n",
      "  \"numInputRows\" : 62,\n",
      "  \"inputRowsPerSecond\" : 31.0,\n",
      "  \"processedRowsPerSecond\" : 452.5547445255474,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 53,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 23,\n",
      "    \"latestOffset\" : 20,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 137,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 14\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 15\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 62,\n",
      "    \"inputRowsPerSecond\" : 31.0,\n",
      "    \"processedRowsPerSecond\" : 452.5547445255474\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 10\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:08.000Z\",\n",
      "  \"batchId\" : 15,\n",
      "  \"numInputRows\" : 62,\n",
      "  \"inputRowsPerSecond\" : 31.0,\n",
      "  \"processedRowsPerSecond\" : 452.5547445255474,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 53,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 23,\n",
      "    \"latestOffset\" : 20,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 137,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 14\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 15\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 62,\n",
      "    \"inputRowsPerSecond\" : 31.0,\n",
      "    \"processedRowsPerSecond\" : 452.5547445255474\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 10\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "-------------------------------------------\n",
      "Batch: 16\n",
      "-------------------------------------------\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                               |date      |time    |level|message                  |server_node  |\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:08:05, ERROR, Connection-timeout, server-node-2]        |2025-04-02|20:08:05|ERROR|Connection-timeout       |server-node-2|\n",
      "|[2025-04-02, 20:08:05, ERROR, 500-Internal, Server-Error, server-node-3]|2025-04-02|20:08:05|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:08:05, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:05|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:05, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:05|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:05, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:05|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:05, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:05|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:05, ERROR, Connection-timeout, server-node-3]        |2025-04-02|20:08:05|ERROR|Connection-timeout       |server-node-3|\n",
      "|[2025-04-02, 20:08:05, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:05|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:05, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:05|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:05, ERROR, 500-Internal, Server-Error, server-node-1]|2025-04-02|20:08:05|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:08:05, ERROR, 404-Not-Found, server-node-3]             |2025-04-02|20:08:05|ERROR|404-Not-Found            |server-node-3|\n",
      "|[2025-04-02, 20:08:05, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:05|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:10.000Z\",\n",
      "  \"batchId\" : 16,\n",
      "  \"numInputRows\" : 57,\n",
      "  \"inputRowsPerSecond\" : 28.5,\n",
      "  \"processedRowsPerSecond\" : 431.8181818181818,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 49,\n",
      "    \"commitOffsets\" : 21,\n",
      "    \"getBatch\" : 21,\n",
      "    \"latestOffset\" : 19,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 132,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 15\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 16\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 57,\n",
      "    \"inputRowsPerSecond\" : 28.5,\n",
      "    \"processedRowsPerSecond\" : 431.8181818181818\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 12\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:10.000Z\",\n",
      "  \"batchId\" : 16,\n",
      "  \"numInputRows\" : 57,\n",
      "  \"inputRowsPerSecond\" : 28.5,\n",
      "  \"processedRowsPerSecond\" : 431.8181818181818,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 49,\n",
      "    \"commitOffsets\" : 21,\n",
      "    \"getBatch\" : 21,\n",
      "    \"latestOffset\" : 19,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 132,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 15\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 16\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 57,\n",
      "    \"inputRowsPerSecond\" : 28.5,\n",
      "    \"processedRowsPerSecond\" : 431.8181818181818\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 12\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:10.000Z\",\n",
      "  \"batchId\" : 16,\n",
      "  \"numInputRows\" : 57,\n",
      "  \"inputRowsPerSecond\" : 28.5,\n",
      "  \"processedRowsPerSecond\" : 431.8181818181818,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 49,\n",
      "    \"commitOffsets\" : 21,\n",
      "    \"getBatch\" : 21,\n",
      "    \"latestOffset\" : 19,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 132,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 15\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 16\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 57,\n",
      "    \"inputRowsPerSecond\" : 28.5,\n",
      "    \"processedRowsPerSecond\" : 431.8181818181818\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 12\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "-------------------------------------------\n",
      "Batch: 17\n",
      "-------------------------------------------\n",
      "+-----------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                              |date      |time    |level|message                  |server_node  |\n",
      "+-----------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:08:07, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:08:07|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:07, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:08:07|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:07, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:08:07|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:07, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:08:07|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:07, ERROR, 404-Not-Found, server-node-2]            |2025-04-02|20:08:07|ERROR|404-Not-Found            |server-node-2|\n",
      "|[2025-04-02, 20:08:07, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:08:07|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:07, ERROR, Connection-timeout, server-node-2]       |2025-04-02|20:08:07|ERROR|Connection-timeout       |server-node-2|\n",
      "|[2025-04-02, 20:08:07, ERROR, 404-Not-Found, server-node-3]            |2025-04-02|20:08:07|ERROR|404-Not-Found            |server-node-3|\n",
      "|[2025-04-02, 20:08:07, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:08:07|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:07, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:08:07|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:07, ERROR, 500-Internal-Server-Error, server-node-2]|2025-04-02|20:08:07|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "+-----------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:12.000Z\",\n",
      "  \"batchId\" : 17,\n",
      "  \"numInputRows\" : 50,\n",
      "  \"inputRowsPerSecond\" : 25.0,\n",
      "  \"processedRowsPerSecond\" : 186.56716417910448,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 56,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 21,\n",
      "    \"latestOffset\" : 150,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 268,\n",
      "    \"walCommit\" : 18\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 16\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 17\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 50,\n",
      "    \"inputRowsPerSecond\" : 25.0,\n",
      "    \"processedRowsPerSecond\" : 186.56716417910448\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 11\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:12.000Z\",\n",
      "  \"batchId\" : 17,\n",
      "  \"numInputRows\" : 50,\n",
      "  \"inputRowsPerSecond\" : 25.0,\n",
      "  \"processedRowsPerSecond\" : 186.56716417910448,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 56,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 21,\n",
      "    \"latestOffset\" : 150,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 268,\n",
      "    \"walCommit\" : 18\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 16\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 17\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 50,\n",
      "    \"inputRowsPerSecond\" : 25.0,\n",
      "    \"processedRowsPerSecond\" : 186.56716417910448\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 11\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:12.000Z\",\n",
      "  \"batchId\" : 17,\n",
      "  \"numInputRows\" : 50,\n",
      "  \"inputRowsPerSecond\" : 25.0,\n",
      "  \"processedRowsPerSecond\" : 186.56716417910448,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 56,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 21,\n",
      "    \"latestOffset\" : 150,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 268,\n",
      "    \"walCommit\" : 18\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 16\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 17\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 50,\n",
      "    \"inputRowsPerSecond\" : 25.0,\n",
      "    \"processedRowsPerSecond\" : 186.56716417910448\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 11\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "-------------------------------------------\n",
      "Batch: 18\n",
      "-------------------------------------------\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                               |date      |time    |level|message                  |server_node  |\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:08:08, ERROR, 404-Not-Found, server-node-2]             |2025-04-02|20:08:08|ERROR|404-Not-Found            |server-node-2|\n",
      "|[2025-04-02, 20:08:08, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:08|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:08, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:08|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:08, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:08|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:08, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:08|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:08, ERROR, 404-Not-Found, server-node-2]             |2025-04-02|20:08:08|ERROR|404-Not-Found            |server-node-2|\n",
      "|[2025-04-02, 20:08:08, ERROR, Connection-timeout, server-node-3]        |2025-04-02|20:08:08|ERROR|Connection-timeout       |server-node-3|\n",
      "|[2025-04-02, 20:08:08, ERROR, Connection-timeout, server-node-1]        |2025-04-02|20:08:08|ERROR|Connection-timeout       |server-node-1|\n",
      "|[2025-04-02, 20:08:08, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:08|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:08, ERROR, Connection-timeout, server-node-2]        |2025-04-02|20:08:08|ERROR|Connection-timeout       |server-node-2|\n",
      "|[2025-04-02, 20:08:08, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:08|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:08, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:08|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:08, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:08|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:08, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:08|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:08, ERROR, 500-Internal, Server-Error, server-node-3]|2025-04-02|20:08:08|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:08:08, ERROR, Connection-timeout, server-node-1]        |2025-04-02|20:08:08|ERROR|Connection-timeout       |server-node-1|\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:14.000Z\",\n",
      "  \"batchId\" : 18,\n",
      "  \"numInputRows\" : 64,\n",
      "  \"inputRowsPerSecond\" : 32.0,\n",
      "  \"processedRowsPerSecond\" : 467.1532846715328,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 49,\n",
      "    \"commitOffsets\" : 21,\n",
      "    \"getBatch\" : 23,\n",
      "    \"latestOffset\" : 21,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 137,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 17\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 18\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 64,\n",
      "    \"inputRowsPerSecond\" : 32.0,\n",
      "    \"processedRowsPerSecond\" : 467.1532846715328\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 16\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:14.000Z\",\n",
      "  \"batchId\" : 18,\n",
      "  \"numInputRows\" : 64,\n",
      "  \"inputRowsPerSecond\" : 32.0,\n",
      "  \"processedRowsPerSecond\" : 467.1532846715328,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 49,\n",
      "    \"commitOffsets\" : 21,\n",
      "    \"getBatch\" : 23,\n",
      "    \"latestOffset\" : 21,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 137,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 17\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 18\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 64,\n",
      "    \"inputRowsPerSecond\" : 32.0,\n",
      "    \"processedRowsPerSecond\" : 467.1532846715328\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 16\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:14.000Z\",\n",
      "  \"batchId\" : 18,\n",
      "  \"numInputRows\" : 64,\n",
      "  \"inputRowsPerSecond\" : 32.0,\n",
      "  \"processedRowsPerSecond\" : 467.1532846715328,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 49,\n",
      "    \"commitOffsets\" : 21,\n",
      "    \"getBatch\" : 23,\n",
      "    \"latestOffset\" : 21,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 137,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 17\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 18\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 64,\n",
      "    \"inputRowsPerSecond\" : 32.0,\n",
      "    \"processedRowsPerSecond\" : 467.1532846715328\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 16\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "-------------------------------------------\n",
      "Batch: 19\n",
      "-------------------------------------------\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                               |date      |time    |level|message                  |server_node  |\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:08:10, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:10|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:10, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:10|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:10, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:10|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:10, ERROR, 500-Internal, Server-Error, server-node-1]|2025-04-02|20:08:10|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:08:10, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:10|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:10, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:10|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:16.000Z\",\n",
      "  \"batchId\" : 19,\n",
      "  \"numInputRows\" : 49,\n",
      "  \"inputRowsPerSecond\" : 24.5,\n",
      "  \"processedRowsPerSecond\" : 357.6642335766423,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 50,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 22,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 137,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 18\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 19\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 49,\n",
      "    \"inputRowsPerSecond\" : 24.5,\n",
      "    \"processedRowsPerSecond\" : 357.6642335766423\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 6\n",
      "  }\n",
      "}\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:16.000Z\",\n",
      "  \"batchId\" : 19,\n",
      "  \"numInputRows\" : 49,\n",
      "  \"inputRowsPerSecond\" : 24.5,\n",
      "  \"processedRowsPerSecond\" : 357.6642335766423,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 50,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 22,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 137,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 18\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 19\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 49,\n",
      "    \"inputRowsPerSecond\" : 24.5,\n",
      "    \"processedRowsPerSecond\" : 357.6642335766423\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 6\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/spark-3.5.4-bin-hadoop3-scala2.13/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/spark-3.5.4-bin-hadoop3-scala2.13/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m logs_df\u001b[38;5;241m.\u001b[39mwriteStream \\\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;241m.\u001b[39moutputMode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39mtrigger(processingTime\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2 seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsole\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruncate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfalse\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m----> 8\u001b[0m \u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/spark-3.5.4-bin-hadoop3-scala2.13/python/pyspark/sql/streaming/query.py:221\u001b[0m, in \u001b[0;36mStreamingQuery.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsq\u001b[38;5;241m.\u001b[39mawaitTermination(\u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/spark-3.5.4-bin-hadoop3-scala2.13/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/opt/conda/spark-3.5.4-bin-hadoop3-scala2.13/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/opt/conda/spark-3.5.4-bin-hadoop3-scala2.13/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mreadline()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:16.000Z\",\n",
      "  \"batchId\" : 19,\n",
      "  \"numInputRows\" : 49,\n",
      "  \"inputRowsPerSecond\" : 24.5,\n",
      "  \"processedRowsPerSecond\" : 357.6642335766423,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 50,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 22,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 137,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 18\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 19\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 49,\n",
      "    \"inputRowsPerSecond\" : 24.5,\n",
      "    \"processedRowsPerSecond\" : 357.6642335766423\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 6\n",
      "  }\n",
      "}\n",
      "-------------------------------------------\n",
      "Batch: 20\n",
      "-------------------------------------------\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                               |date      |time    |level|message                  |server_node  |\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:08:12, ERROR, 404-Not-Found, server-node-2]             |2025-04-02|20:08:12|ERROR|404-Not-Found            |server-node-2|\n",
      "|[2025-04-02, 20:08:12, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:12|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:12, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:12|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:12, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:12|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:12, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:12|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:12, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:12|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:12, ERROR, 500-Internal, Server-Error, server-node-3]|2025-04-02|20:08:12|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:08:12, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:12|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:12, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:12|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:12, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:12|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:12, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:12|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:12, ERROR, 500-Internal, Server-Error, server-node-3]|2025-04-02|20:08:12|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:08:12, ERROR, Connection-timeout, server-node-2]        |2025-04-02|20:08:12|ERROR|Connection-timeout       |server-node-2|\n",
      "|[2025-04-02, 20:08:12, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:12|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:12, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:12|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:12, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:12|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:12, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:12|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:12, ERROR, 500-Internal, Server-Error, server-node-2]|2025-04-02|20:08:12|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:08:12, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:12|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:12, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:12|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:18.000Z\",\n",
      "  \"batchId\" : 20,\n",
      "  \"numInputRows\" : 62,\n",
      "  \"inputRowsPerSecond\" : 31.0,\n",
      "  \"processedRowsPerSecond\" : 218.3098591549296,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 49,\n",
      "    \"commitOffsets\" : 21,\n",
      "    \"getBatch\" : 21,\n",
      "    \"latestOffset\" : 172,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 284,\n",
      "    \"walCommit\" : 18\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 19\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 20\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 62,\n",
      "    \"inputRowsPerSecond\" : 31.0,\n",
      "    \"processedRowsPerSecond\" : 218.3098591549296\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 22\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:18.000Z\",\n",
      "  \"batchId\" : 20,\n",
      "  \"numInputRows\" : 62,\n",
      "  \"inputRowsPerSecond\" : 31.0,\n",
      "  \"processedRowsPerSecond\" : 218.3098591549296,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 49,\n",
      "    \"commitOffsets\" : 21,\n",
      "    \"getBatch\" : 21,\n",
      "    \"latestOffset\" : 172,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 284,\n",
      "    \"walCommit\" : 18\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 19\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 20\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 62,\n",
      "    \"inputRowsPerSecond\" : 31.0,\n",
      "    \"processedRowsPerSecond\" : 218.3098591549296\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 22\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:18.000Z\",\n",
      "  \"batchId\" : 20,\n",
      "  \"numInputRows\" : 62,\n",
      "  \"inputRowsPerSecond\" : 31.0,\n",
      "  \"processedRowsPerSecond\" : 218.3098591549296,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 49,\n",
      "    \"commitOffsets\" : 21,\n",
      "    \"getBatch\" : 21,\n",
      "    \"latestOffset\" : 172,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 284,\n",
      "    \"walCommit\" : 18\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 19\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 20\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 62,\n",
      "    \"inputRowsPerSecond\" : 31.0,\n",
      "    \"processedRowsPerSecond\" : 218.3098591549296\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 22\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "-------------------------------------------\n",
      "Batch: 21\n",
      "-------------------------------------------\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                               |date      |time    |level|message                  |server_node  |\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:08:14, ERROR, 404-Not-Found, server-node-2]             |2025-04-02|20:08:14|ERROR|404-Not-Found            |server-node-2|\n",
      "|[2025-04-02, 20:08:14, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:14|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:14, ERROR, 500-Internal, Server-Error, server-node-2]|2025-04-02|20:08:14|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:08:14, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:14|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:14, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:14|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:14, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:14|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:14, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:14|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:14, ERROR, 404-Not-Found, server-node-1]             |2025-04-02|20:08:14|ERROR|404-Not-Found            |server-node-1|\n",
      "|[2025-04-02, 20:08:14, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:14|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:14, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:14|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:14, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:14|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:14, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:14|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:14, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:14|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:14, ERROR, Connection-timeout, server-node-2]        |2025-04-02|20:08:14|ERROR|Connection-timeout       |server-node-2|\n",
      "|[2025-04-02, 20:08:14, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:14|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:14, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:14|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:14, ERROR, 500-Internal, Server-Error, server-node-3]|2025-04-02|20:08:14|ERROR|500-Internal             |Server-Error |\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:20.000Z\",\n",
      "  \"batchId\" : 21,\n",
      "  \"numInputRows\" : 58,\n",
      "  \"inputRowsPerSecond\" : 29.0,\n",
      "  \"processedRowsPerSecond\" : 417.2661870503597,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 53,\n",
      "    \"commitOffsets\" : 21,\n",
      "    \"getBatch\" : 23,\n",
      "    \"latestOffset\" : 20,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 139,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 20\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 21\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 58,\n",
      "    \"inputRowsPerSecond\" : 29.0,\n",
      "    \"processedRowsPerSecond\" : 417.2661870503597\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 17\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:20.000Z\",\n",
      "  \"batchId\" : 21,\n",
      "  \"numInputRows\" : 58,\n",
      "  \"inputRowsPerSecond\" : 29.0,\n",
      "  \"processedRowsPerSecond\" : 417.2661870503597,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 53,\n",
      "    \"commitOffsets\" : 21,\n",
      "    \"getBatch\" : 23,\n",
      "    \"latestOffset\" : 20,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 139,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 20\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 21\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 58,\n",
      "    \"inputRowsPerSecond\" : 29.0,\n",
      "    \"processedRowsPerSecond\" : 417.2661870503597\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 17\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:20.000Z\",\n",
      "  \"batchId\" : 21,\n",
      "  \"numInputRows\" : 58,\n",
      "  \"inputRowsPerSecond\" : 29.0,\n",
      "  \"processedRowsPerSecond\" : 417.2661870503597,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 53,\n",
      "    \"commitOffsets\" : 21,\n",
      "    \"getBatch\" : 23,\n",
      "    \"latestOffset\" : 20,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 139,\n",
      "    \"walCommit\" : 19\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 20\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 21\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 58,\n",
      "    \"inputRowsPerSecond\" : 29.0,\n",
      "    \"processedRowsPerSecond\" : 417.2661870503597\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 17\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "-------------------------------------------\n",
      "Batch: 22\n",
      "-------------------------------------------\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                               |date      |time    |level|message                  |server_node  |\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:08:16, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:16|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:16, ERROR, Connection-timeout, server-node-2]        |2025-04-02|20:08:16|ERROR|Connection-timeout       |server-node-2|\n",
      "|[2025-04-02, 20:08:16, ERROR, 500-Internal, Server-Error, server-node-3]|2025-04-02|20:08:16|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:08:16, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:16|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:16, ERROR, Connection-timeout, server-node-1]        |2025-04-02|20:08:16|ERROR|Connection-timeout       |server-node-1|\n",
      "|[2025-04-02, 20:08:16, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:16|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:16, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:16|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:16, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:16|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:16, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:16|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:16, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:16|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:16, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:16|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:22.001Z\",\n",
      "  \"batchId\" : 22,\n",
      "  \"numInputRows\" : 60,\n",
      "  \"inputRowsPerSecond\" : 29.985007496251875,\n",
      "  \"processedRowsPerSecond\" : 444.4444444444444,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 51,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 19,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 135,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 21\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 22\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 60,\n",
      "    \"inputRowsPerSecond\" : 29.985007496251875,\n",
      "    \"processedRowsPerSecond\" : 444.4444444444444\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 11\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:22.001Z\",\n",
      "  \"batchId\" : 22,\n",
      "  \"numInputRows\" : 60,\n",
      "  \"inputRowsPerSecond\" : 29.985007496251875,\n",
      "  \"processedRowsPerSecond\" : 444.4444444444444,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 51,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 19,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 135,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 21\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 22\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 60,\n",
      "    \"inputRowsPerSecond\" : 29.985007496251875,\n",
      "    \"processedRowsPerSecond\" : 444.4444444444444\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 11\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:22.001Z\",\n",
      "  \"batchId\" : 22,\n",
      "  \"numInputRows\" : 60,\n",
      "  \"inputRowsPerSecond\" : 29.985007496251875,\n",
      "  \"processedRowsPerSecond\" : 444.4444444444444,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 51,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 19,\n",
      "    \"queryPlanning\" : 3,\n",
      "    \"triggerExecution\" : 135,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 21\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 22\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 60,\n",
      "    \"inputRowsPerSecond\" : 29.985007496251875,\n",
      "    \"processedRowsPerSecond\" : 444.4444444444444\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 11\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "-------------------------------------------\n",
      "Batch: 23\n",
      "-------------------------------------------\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                               |date      |time    |level|message                  |server_node  |\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:08:19, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:19|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:19, ERROR, 404-Not-Found, server-node-1]             |2025-04-02|20:08:19|ERROR|404-Not-Found            |server-node-1|\n",
      "|[2025-04-02, 20:08:19, ERROR, 500-Internal, Server-Error, server-node-2]|2025-04-02|20:08:19|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:08:19, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:19|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:19, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:19|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:19, ERROR, 500-Internal, Server-Error, server-node-3]|2025-04-02|20:08:19|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:08:19, ERROR, 500-Internal, Server-Error, server-node-2]|2025-04-02|20:08:19|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:08:19, ERROR, 500-Internal, Server-Error, server-node-2]|2025-04-02|20:08:19|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:08:19, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:19|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:19, ERROR, 404-Not-Found, server-node-3]             |2025-04-02|20:08:19|ERROR|404-Not-Found            |server-node-3|\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:24.000Z\",\n",
      "  \"batchId\" : 23,\n",
      "  \"numInputRows\" : 66,\n",
      "  \"inputRowsPerSecond\" : 33.01650825412706,\n",
      "  \"processedRowsPerSecond\" : 215.68627450980392,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 50,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 190,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 306,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 22\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 23\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 66,\n",
      "    \"inputRowsPerSecond\" : 33.01650825412706,\n",
      "    \"processedRowsPerSecond\" : 215.68627450980392\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 10\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:24.000Z\",\n",
      "  \"batchId\" : 23,\n",
      "  \"numInputRows\" : 66,\n",
      "  \"inputRowsPerSecond\" : 33.01650825412706,\n",
      "  \"processedRowsPerSecond\" : 215.68627450980392,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 50,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 190,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 306,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 22\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 23\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 66,\n",
      "    \"inputRowsPerSecond\" : 33.01650825412706,\n",
      "    \"processedRowsPerSecond\" : 215.68627450980392\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 10\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:24.000Z\",\n",
      "  \"batchId\" : 23,\n",
      "  \"numInputRows\" : 66,\n",
      "  \"inputRowsPerSecond\" : 33.01650825412706,\n",
      "  \"processedRowsPerSecond\" : 215.68627450980392,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 50,\n",
      "    \"commitOffsets\" : 20,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 190,\n",
      "    \"queryPlanning\" : 4,\n",
      "    \"triggerExecution\" : 306,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 22\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 23\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 66,\n",
      "    \"inputRowsPerSecond\" : 33.01650825412706,\n",
      "    \"processedRowsPerSecond\" : 215.68627450980392\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 10\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "-------------------------------------------\n",
      "Batch: 24\n",
      "-------------------------------------------\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|log_array                                                               |date      |time    |level|message                  |server_node  |\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "|[2025-04-02, 20:08:21, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:21|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:21, ERROR, 500-Internal, Server-Error, server-node-2]|2025-04-02|20:08:21|ERROR|500-Internal             |Server-Error |\n",
      "|[2025-04-02, 20:08:21, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:21|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:21, ERROR, Connection-timeout, server-node-3]        |2025-04-02|20:08:21|ERROR|Connection-timeout       |server-node-3|\n",
      "|[2025-04-02, 20:08:21, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:21|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "|[2025-04-02, 20:08:21, ERROR, 500-Internal-Server-Error, server-node-2] |2025-04-02|20:08:21|ERROR|500-Internal-Server-Error|server-node-2|\n",
      "+------------------------------------------------------------------------+----------+--------+-----+-------------------------+-------------+\n",
      "\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:26.000Z\",\n",
      "  \"batchId\" : 24,\n",
      "  \"numInputRows\" : 52,\n",
      "  \"inputRowsPerSecond\" : 26.0,\n",
      "  \"processedRowsPerSecond\" : 371.4285714285714,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 51,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 21,\n",
      "    \"queryPlanning\" : 7,\n",
      "    \"triggerExecution\" : 140,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 23\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 24\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 52,\n",
      "    \"inputRowsPerSecond\" : 26.0,\n",
      "    \"processedRowsPerSecond\" : 371.4285714285714\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 6\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:26.000Z\",\n",
      "  \"batchId\" : 24,\n",
      "  \"numInputRows\" : 52,\n",
      "  \"inputRowsPerSecond\" : 26.0,\n",
      "  \"processedRowsPerSecond\" : 371.4285714285714,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 51,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 21,\n",
      "    \"queryPlanning\" : 7,\n",
      "    \"triggerExecution\" : 140,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 23\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 24\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 52,\n",
      "    \"inputRowsPerSecond\" : 26.0,\n",
      "    \"processedRowsPerSecond\" : 371.4285714285714\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 6\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n",
      "Query made progress: {\n",
      "  \"id\" : \"a4a3e10a-3801-4fd6-8a27-4e8ba9b74b14\",\n",
      "  \"runId\" : \"ed7ccddf-3040-42c7-a995-b8dc46bdcb05\",\n",
      "  \"name\" : null,\n",
      "  \"timestamp\" : \"2025-04-03T02:08:26.000Z\",\n",
      "  \"batchId\" : 24,\n",
      "  \"numInputRows\" : 52,\n",
      "  \"inputRowsPerSecond\" : 26.0,\n",
      "  \"processedRowsPerSecond\" : 371.4285714285714,\n",
      "  \"durationMs\" : {\n",
      "    \"addBatch\" : 51,\n",
      "    \"commitOffsets\" : 19,\n",
      "    \"getBatch\" : 22,\n",
      "    \"latestOffset\" : 21,\n",
      "    \"queryPlanning\" : 7,\n",
      "    \"triggerExecution\" : 140,\n",
      "    \"walCommit\" : 20\n",
      "  },\n",
      "  \"stateOperators\" : [ ],\n",
      "  \"sources\" : [ {\n",
      "    \"description\" : \"FileStreamSource[file:/home/jovyan/notebooks/data/log_data/input]\",\n",
      "    \"startOffset\" : {\n",
      "      \"logOffset\" : 23\n",
      "    },\n",
      "    \"endOffset\" : {\n",
      "      \"logOffset\" : 24\n",
      "    },\n",
      "    \"latestOffset\" : null,\n",
      "    \"numInputRows\" : 52,\n",
      "    \"inputRowsPerSecond\" : 26.0,\n",
      "    \"processedRowsPerSecond\" : 371.4285714285714\n",
      "  } ],\n",
      "  \"sink\" : {\n",
      "    \"description\" : \"org.apache.spark.sql.execution.streaming.ConsoleTable$@234cb5f0\",\n",
      "    \"numOutputRows\" : 6\n",
      "  }\n",
      "}\n",
      "High volume of data! Input rows exceed 50.\n"
     ]
    }
   ],
   "source": [
    "query = logs_df.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .trigger(processingTime=\"2 seconds\") \\\n",
    "    .format(\"console\") \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query terminated: c371751e-7a00-46fd-a8d9-6e7a6d620375\n",
      "Query terminated: c371751e-7a00-46fd-a8d9-6e7a6d620375\n",
      "Query terminated: c371751e-7a00-46fd-a8d9-6e7a6d620375\n"
     ]
    }
   ],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
