{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electr칩nica, Sistemas e Inform치tica** </center>\n",
    "---\n",
    "## <center> **Carrera: Ing. en Sistemas Computacionales** </center>\n",
    "---\n",
    "### <center> **Primavera 2025** </center>\n",
    "---\n",
    "\n",
    "**Lab 12**: Recommendation System with ALS\n",
    "\n",
    "**Fecha**: 11 de mayo del 2025\n",
    "\n",
    "**Nombre del Estudiante**: Marco Albanese, Vicente Siloe\n",
    "\n",
    "**Profesor**: Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creacion de la conexi칩n con el cluster de spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MLSpark-Recommender-Systems\") \\\n",
    "    .master(\"spark://2da3617855ce:7077\") \\\n",
    "    .config(\"spark.ui.port\",\"4040\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparaci칩n de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from equipo_mcqueen.spark_utils import SparkUtils\n",
    "\n",
    "movie_ratings_data = [\n",
    "    (\"userId\", \"IntegerType\"),\n",
    "    (\"movieId\", \"IntegerType\"),\n",
    "    (\"rating\", \"IntegerType\"),\n",
    "    (\"date\", \"TimestampType\")\n",
    "]\n",
    "\n",
    "ratings_schema = SparkUtils.generate_schema(movie_ratings_data)\n",
    "\n",
    "ratings_df = spark.read.schema(ratings_schema).option(\"header\", \"false\").option(\"delimiter\", \"::\").csv(\"/home/jovyan/notebooks/data/sample_movielens_ratings.txt\")\n",
    "ratings_df = ratings_df.drop(\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure ALS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als = ALS(\n",
    "    userCol=\"userId\", \n",
    "    itemCol=\"movieId\", \n",
    "    ratingCol=\"rating\", \n",
    "    maxIter=10, \n",
    "    regParam=0.1, \n",
    "    rank=5, # Controls the dimensionality of the latent vector space for \n",
    "            # users and items.\n",
    "    coldStartStrategy=\"drop\"  # Avoids NaN predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = als.fit(ratings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------------------------------------------------------------------------+\n",
      "|userId|recommendations                                                                      |\n",
      "+------+-------------------------------------------------------------------------------------+\n",
      "|0     |[{92, 2.5840385}, {2, 2.316802}, {62, 2.2325232}, {25, 2.157748}, {93, 2.1528697}]   |\n",
      "|10    |[{92, 2.768342}, {2, 2.6728113}, {93, 2.6242015}, {25, 2.5927775}, {49, 2.5867324}]  |\n",
      "|20    |[{22, 3.5597918}, {68, 3.1278815}, {94, 3.084497}, {51, 3.0827737}, {77, 3.0246763}] |\n",
      "|1     |[{22, 2.9029422}, {68, 2.630123}, {77, 2.5238972}, {62, 2.501064}, {90, 2.4797387}]  |\n",
      "|11    |[{32, 5.082464}, {18, 4.705235}, {30, 4.6826043}, {27, 4.5120797}, {8, 4.229401}]    |\n",
      "|21    |[{29, 4.320379}, {52, 4.2401457}, {76, 3.716108}, {63, 3.5063725}, {53, 3.4859684}]  |\n",
      "|22    |[{51, 4.458179}, {75, 4.418395}, {22, 4.118836}, {74, 4.1007586}, {88, 4.0829244}]   |\n",
      "|2     |[{93, 4.2531066}, {83, 4.1469526}, {8, 4.0344357}, {39, 3.7214603}, {2, 3.6790943}]  |\n",
      "|12    |[{46, 5.763551}, {55, 4.7998195}, {49, 4.545951}, {90, 4.2674875}, {48, 4.1170616}]  |\n",
      "|23    |[{46, 5.4916263}, {55, 4.7129517}, {32, 4.655011}, {90, 4.6475368}, {49, 4.432613}]  |\n",
      "|3     |[{30, 4.089861}, {69, 3.8413658}, {51, 3.807304}, {74, 3.7822077}, {75, 3.7480934}]  |\n",
      "|13    |[{74, 2.7260454}, {93, 2.616767}, {29, 2.5265772}, {53, 2.495797}, {52, 2.447867}]   |\n",
      "|24    |[{52, 4.4483128}, {29, 4.445633}, {30, 3.9009523}, {53, 3.8602533}, {69, 3.7498972}] |\n",
      "|4     |[{29, 3.2479038}, {52, 3.1375268}, {62, 2.8016934}, {93, 2.767445}, {76, 2.758533}]  |\n",
      "|14    |[{29, 4.6415415}, {52, 4.596407}, {76, 3.866494}, {63, 3.81995}, {85, 3.5510547}]    |\n",
      "|5     |[{46, 4.169175}, {90, 3.561502}, {55, 3.322591}, {49, 3.2502005}, {94, 3.189144}]    |\n",
      "|15    |[{46, 3.4862611}, {49, 2.7943614}, {55, 2.670787}, {90, 2.6077518}, {64, 2.45374}]   |\n",
      "|25    |[{46, 3.1664221}, {49, 2.9964566}, {55, 2.5469325}, {93, 2.3547156}, {48, 2.3131235}]|\n",
      "|6     |[{29, 3.1030846}, {52, 3.0379107}, {25, 3.02641}, {2, 2.7636726}, {93, 2.7427537}]   |\n",
      "|16    |[{22, 3.7481875}, {77, 3.6971643}, {90, 3.6679487}, {85, 3.6157954}, {62, 3.5778081}]|\n",
      "+------+-------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Generate recommendations for each user\n",
    "user_recommendations = model.recommendForAllUsers(numItems=5)\n",
    "\n",
    "# Show recommendations\n",
    "user_recommendations.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = [\n",
    "    (16, \"The Matrix\"),\n",
    "    (23, \"Shawshank Redemption\"),\n",
    "    (41, \"The Dark Knight\"),\n",
    "    (55, \"Inception\"),\n",
    "    (79, \"The Lord of the Rings: The Return of the King\")\n",
    "]\n",
    "\n",
    "movies_schema = SparkUtils.generate_schema([\n",
    "    (\"movieId\", \"IntegerType\"),\n",
    "    (\"title\", \"StringType\")\n",
    "])\n",
    "\n",
    "movies_df = spark.createDataFrame(movies, schema=movies_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 601:>                                                        (0 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+---------+\n",
      "|movieId|title               |rating   |\n",
      "+-------+--------------------+---------+\n",
      "|23     |Shawshank Redemption|3.1364992|\n",
      "|55     |Inception           |3.4145792|\n",
      "|55     |Inception           |3.9458332|\n",
      "|55     |Inception           |2.5469325|\n",
      "|55     |Inception           |2.670787 |\n",
      "|55     |Inception           |3.322591 |\n",
      "|55     |Inception           |4.7129517|\n",
      "|55     |Inception           |4.7998195|\n",
      "+-------+--------------------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "\n",
    "# Explode recommendations for easier reading\n",
    "recommendations = user_recommendations.select(\"userId\", explode(\"recommendations\").alias(\"rec\"))\n",
    "recommendations = recommendations.join(movies_df, recommendations.rec.movieId == movies_df.movieId).select(\"movieId\", \"title\", \"rec.rating\")\n",
    "\n",
    "# Show user-song recommendations with titles\n",
    "recommendations.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions for all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|22    |0      |1     |0.96697557|\n",
      "|22    |3      |2     |1.6326257 |\n",
      "|22    |5      |2     |2.0366673 |\n",
      "|22    |6      |2     |2.2972772 |\n",
      "|22    |9      |1     |1.5513803 |\n",
      "|22    |10     |1     |1.4349127 |\n",
      "|22    |11     |1     |1.2901659 |\n",
      "|22    |13     |1     |1.617328  |\n",
      "|22    |14     |1     |1.389045  |\n",
      "|22    |16     |1     |0.7093756 |\n",
      "|22    |18     |3     |3.0116072 |\n",
      "|22    |19     |1     |1.4644071 |\n",
      "|22    |22     |5     |4.118836  |\n",
      "|22    |25     |1     |0.97840077|\n",
      "|22    |26     |1     |1.1323681 |\n",
      "|22    |29     |3     |3.2431226 |\n",
      "|22    |30     |5     |3.9942718 |\n",
      "|22    |32     |4     |3.217519  |\n",
      "|22    |33     |1     |0.8903809 |\n",
      "|22    |35     |1     |0.7503733 |\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(ratings_df)\n",
    "predictions.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error (RMSE) = 0.5691166521341573\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Set up evaluator to compute RMSE\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", \n",
    "    labelCol=\"rating\", \n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root-mean-square error (RMSE) = {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
