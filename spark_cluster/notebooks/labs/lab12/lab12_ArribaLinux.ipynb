{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../labs/img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electrónica, Sistemas e Informática** </center>\n",
    "---\n",
    "## <center> **Procesamiento de Datos Masivos** </center>\n",
    "---\n",
    "### <center> **Primavera 2025** </center>\n",
    "---\n",
    "### <center> **Lab 12** </center>\n",
    "\n",
    "---\n",
    "\n",
    "**Fecha**: 11 Mayo 2025\n",
    "\n",
    "**Nombre del Equipo**: Arriba Linux\n",
    "\n",
    "**Integrantes del Equipo**: Tirzah Peniche Barba / Ana Cristina Luna Arellano / Juan Pedro Bihouet\n",
    "\n",
    "**Profesor**: Dr. Pablo Camarillo Ramirez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creacion de la conexión con el cluster de spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ALS-Movie-Recommendation\") \\\n",
    "    .master(\"spark://28d4ad191d34:7077\") \\\n",
    "    .config(\"spark.ui.port\",\"4040\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.functions import col\n",
    "from ArribaLinux.spark_utils import SparkUtils\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType, LongType\n",
    "\n",
    "#path\n",
    "ratings_path = \"/home/jovyan/notebooks/data/ratings.txt\" \n",
    "#creamos el df con las columnas que nos pide\n",
    "ratings_schema = StructType([\n",
    "    StructField(\"userId\", IntegerType(), True),\n",
    "    StructField(\"movieId\", IntegerType(), True),\n",
    "    StructField(\"rating\", FloatType(), True),\n",
    "    StructField(\"timestamp\", LongType(), True)\n",
    "])\n",
    "\n",
    "ratings_df = spark.read.csv(\n",
    "    ratings_path,\n",
    "    sep=\"::\",              # <-- delimiter (el file no se me descargaba como .csv encontre esto para separarlo)\n",
    "    schema=ratings_schema,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "#generamos el modelo ALS\n",
    "als = ALS(\n",
    "    maxIter=10,\n",
    "    regParam=0.1,\n",
    "    userCol=\"userId\",\n",
    "    itemCol=\"movieId\",\n",
    "    ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = als.fit(ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+----------+\n",
      "|userId|movieId|rating|timestamp |prediction|\n",
      "+------+-------+------+----------+----------+\n",
      "|28    |0      |3.0   |1424380312|2.6242466 |\n",
      "|28    |1      |1.0   |1424380312|1.1713365 |\n",
      "|28    |2      |4.0   |1424380312|3.649982  |\n",
      "|28    |3      |1.0   |1424380312|0.8008682 |\n",
      "|28    |6      |1.0   |1424380312|0.9787566 |\n",
      "|28    |7      |1.0   |1424380312|1.3701822 |\n",
      "|28    |12     |5.0   |1424380312|3.5106254 |\n",
      "|28    |13     |2.0   |1424380312|2.022234  |\n",
      "|28    |14     |1.0   |1424380312|1.0674466 |\n",
      "|28    |15     |1.0   |1424380312|1.0844364 |\n",
      "|28    |17     |1.0   |1424380312|0.94172955|\n",
      "|28    |19     |3.0   |1424380312|2.665203  |\n",
      "|28    |20     |1.0   |1424380312|0.92025286|\n",
      "|28    |23     |3.0   |1424380312|2.7755823 |\n",
      "|28    |24     |3.0   |1424380312|2.2836795 |\n",
      "|28    |27     |1.0   |1424380312|1.0695844 |\n",
      "|28    |29     |1.0   |1424380312|1.1772664 |\n",
      "|28    |33     |1.0   |1424380312|1.2561624 |\n",
      "|28    |34     |1.0   |1424380312|1.203549  |\n",
      "|28    |36     |1.0   |1424380312|1.1647482 |\n",
      "+------+-------+------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 110:==================================>                   (64 + 1) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------------------------+\n",
      "|userId|recommendations                   |\n",
      "+------+----------------------------------+\n",
      "|20    |[{22, 3.6024003}, {94, 3.2383304}]|\n",
      "|10    |[{92, 3.2280664}, {2, 3.121109}]  |\n",
      "|0     |[{92, 3.0114312}, {2, 2.6349454}] |\n",
      "|1     |[{68, 3.0046268}, {62, 2.9320545}]|\n",
      "|21    |[{29, 4.3229423}, {52, 4.2465305}]|\n",
      "|11    |[{30, 4.767297}, {32, 4.7413015}] |\n",
      "|12    |[{46, 5.2744637}, {90, 4.6326585}]|\n",
      "|22    |[{75, 4.5294313}, {51, 4.349877}] |\n",
      "|2     |[{93, 4.490622}, {83, 4.335734}]  |\n",
      "|13    |[{93, 2.979865}, {74, 2.8578439}] |\n",
      "|3     |[{51, 4.097765}, {75, 4.0294666}] |\n",
      "|23    |[{46, 4.794603}, {32, 4.746082}]  |\n",
      "|4     |[{53, 3.4589245}, {29, 3.3570633}]|\n",
      "|24    |[{52, 4.433993}, {69, 4.417164}]  |\n",
      "|14    |[{52, 4.6393085}, {29, 4.550998}] |\n",
      "|5     |[{55, 3.6768343}, {90, 3.5640485}]|\n",
      "|15    |[{46, 3.9592383}, {90, 3.07912}]  |\n",
      "|25    |[{71, 2.8628864}, {47, 2.752271}] |\n",
      "|26    |[{51, 4.951104}, {22, 4.8334303}] |\n",
      "|6     |[{25, 3.6855323}, {29, 3.1586406}]|\n",
      "+------+----------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(ratings_df)\n",
    "\n",
    "predictions.show(truncate=False)\n",
    "\n",
    "recommended = model.recommendForAllUsers(numItems=2)\n",
    "recommended.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error (RMSE): 0.4010\n"
     ]
    }
   ],
   "source": [
    "#Evaluamos el performance \n",
    "valuator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root-mean-square error (RMSE): {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
