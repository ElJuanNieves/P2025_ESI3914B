{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src=\"../img/ITESOLogo.png\" alt=\"ITESO\" width=\"480\" height=\"130\"> </center>\n",
    "# <center> **Departamento de Electr칩nica, Sistemas e Inform치tica** </center>\n",
    "---\n",
    "## <center> **Procesamiento de Datos Masivos** </center>\n",
    "---\n",
    "### <center> **Primavera 2025** </center>\n",
    "---\n",
    "### <center> **Code Lab 12: Recommendation System with ALS** </center>\n",
    "\n",
    "---\n",
    "**Alumnos**: David Abraham Naranjo Salgado, Benjamin Zarate y Angel Cortes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creacion de la conexi칩n con el cluster de spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/08 01:02:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MLSpark-Recommender-Systems\") \\\n",
    "    .master(\"spark://2c9c6f7ab23e:7077\") \\\n",
    "    .config(\"spark.ui.port\",\"4040\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparaci칩n de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     0|      2|     3|     NULL|\n",
      "|     0|      3|     1|     NULL|\n",
      "|     0|      5|     2|     NULL|\n",
      "|     0|      9|     4|     NULL|\n",
      "|     0|     11|     1|     NULL|\n",
      "+------+-------+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from team_name.spark_utils import SparkUtils\n",
    "\n",
    "data = \"/home/jovyan/notebooks/data/sample_movielens_ratings.txt\"\n",
    "# Define schema for the DataFrame\n",
    "schema = SparkUtils.generate_schema([(\"userId\", \"integer\"), (\"movieId\", \"integer\"), (\"rating\", \"integer\"), (\"timestamp\", \"timestamp\")])\n",
    "\n",
    "df = spark.read.schema(schema).option(\"header\", \"false\").option(\"delimiter\", \"::\").csv(data)\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     0|      2|     3|\n",
      "|     0|      3|     1|\n",
      "|     0|      5|     2|\n",
      "|     0|      9|     4|\n",
      "|     0|     11|     1|\n",
      "+------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(\"timestamp\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure ALS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als = ALS(\n",
    "    userCol=\"userId\", \n",
    "    itemCol=\"movieId\", \n",
    "    ratingCol=\"rating\", \n",
    "    maxIter=16, \n",
    "    regParam=0.1, \n",
    "    rank=5, # Controls the dimensionality of the latent vector space for \n",
    "            # users and items.\n",
    "    coldStartStrategy=\"drop\"  # Avoids NaN predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = als.fit(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 836:============================================>         (82 + 1) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------------------------------------------------------------------------+\n",
      "|userId|recommendations                                                                      |\n",
      "+------+-------------------------------------------------------------------------------------+\n",
      "|0     |[{92, 2.5936005}, {2, 2.3094485}, {62, 2.2523856}, {25, 2.1904168}, {93, 2.1489012}] |\n",
      "|10    |[{92, 2.775433}, {2, 2.6526644}, {25, 2.638788}, {93, 2.610295}, {49, 2.584126}]     |\n",
      "|20    |[{22, 3.5625312}, {68, 3.118233}, {94, 3.0791268}, {51, 3.0760531}, {77, 3.0344026}] |\n",
      "|1     |[{22, 2.9020486}, {68, 2.611147}, {77, 2.5359411}, {62, 2.502466}, {90, 2.4866726}]  |\n",
      "|11    |[{32, 5.046121}, {30, 4.6833315}, {18, 4.6645722}, {27, 4.486559}, {8, 4.1586075}]   |\n",
      "|21    |[{29, 4.324222}, {52, 4.246}, {76, 3.7285264}, {63, 3.5023663}, {53, 3.4783237}]     |\n",
      "|22    |[{51, 4.459827}, {75, 4.4141407}, {22, 4.110449}, {74, 4.095386}, {88, 4.073851}]    |\n",
      "|2     |[{93, 4.236278}, {83, 4.1585765}, {8, 4.050406}, {39, 3.7472708}, {2, 3.5091283}]    |\n",
      "|12    |[{46, 5.7865644}, {55, 4.7923613}, {49, 4.5450253}, {90, 4.2088113}, {48, 4.1131487}]|\n",
      "|23    |[{46, 5.56107}, {55, 4.7296376}, {32, 4.6508827}, {90, 4.6244435}, {49, 4.418753}]   |\n",
      "|3     |[{30, 4.0754194}, {69, 3.8488052}, {51, 3.814089}, {74, 3.810007}, {75, 3.738965}]   |\n",
      "|13    |[{74, 2.7025557}, {93, 2.6150029}, {29, 2.5301332}, {53, 2.4688735}, {52, 2.4611433}]|\n",
      "|24    |[{29, 4.4325514}, {52, 4.4313855}, {30, 3.9022346}, {53, 3.883326}, {69, 3.7378824}] |\n",
      "|4     |[{29, 3.2474868}, {52, 3.1382415}, {62, 2.8144667}, {93, 2.7525275}, {76, 2.7389035}]|\n",
      "|14    |[{29, 4.6384683}, {52, 4.5939603}, {76, 3.8841715}, {63, 3.826207}, {85, 3.5401702}] |\n",
      "|5     |[{46, 4.179557}, {90, 3.5503592}, {55, 3.3173132}, {49, 3.259511}, {94, 3.1850147}]  |\n",
      "|15    |[{46, 3.4423566}, {49, 2.8109586}, {55, 2.6372945}, {90, 2.5439525}, {64, 2.4188104}]|\n",
      "|25    |[{46, 3.131411}, {49, 3.0103557}, {55, 2.4992392}, {93, 2.4271278}, {48, 2.2946918}] |\n",
      "|6     |[{29, 3.0943303}, {52, 3.0269623}, {25, 3.0235324}, {2, 2.776898}, {93, 2.7532473}]  |\n",
      "|16    |[{22, 3.7506073}, {77, 3.7133472}, {90, 3.6291158}, {62, 3.5777874}, {85, 3.5730505}]|\n",
      "+------+-------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Generate recommendations for each user\n",
    "user_recommendations = model.recommendForAllUsers(numItems=5)\n",
    "\n",
    "# Show recommendations\n",
    "user_recommendations.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions for all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|22    |0      |1     |0.95978665|\n",
      "|22    |3      |2     |1.625176  |\n",
      "|22    |5      |2     |2.035528  |\n",
      "|22    |6      |2     |2.2916586 |\n",
      "|22    |9      |1     |1.5355445 |\n",
      "|22    |10     |1     |1.4313806 |\n",
      "|22    |11     |1     |1.2968231 |\n",
      "|22    |13     |1     |1.5995504 |\n",
      "|22    |14     |1     |1.38723   |\n",
      "|22    |16     |1     |0.70297694|\n",
      "|22    |18     |3     |3.0267131 |\n",
      "|22    |19     |1     |1.4562871 |\n",
      "|22    |22     |5     |4.1104484 |\n",
      "|22    |25     |1     |0.98768014|\n",
      "|22    |26     |1     |1.1374228 |\n",
      "|22    |29     |3     |3.2444606 |\n",
      "|22    |30     |5     |3.9997764 |\n",
      "|22    |32     |4     |3.1884887 |\n",
      "|22    |33     |1     |0.9095676 |\n",
      "|22    |35     |1     |0.7483205 |\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(df)\n",
    "predictions.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error (RMSE) = 0.5693376676367434\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Set up evaluator to compute RMSE\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\", \n",
    "    labelCol=\"rating\", \n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root-mean-square error (RMSE) = {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
